# Story 5.2: Duplicati Backup System

## Status
Draft

## Story
**As a** backup specialist,
**I want** Duplicati 2.1.1.102 deployed with automation,
**so that** all critical data is regularly backed up to external storage.

## Acceptance Criteria
1. Duplicati container running with specified version
2. Backup sources properly configured (databases, files)
3. Backup destinations and schedules set
4. Encryption and compression enabled
5. Backup verification and testing procedures
6. Restoration procedure documented and tested
7. Full restore test performed successfully from backup
8. Restore time benchmarks established

## Tasks / Subtasks

- [ ] **Task 0: Verify Prerequisites and Review Backup Strategy** (AC: 1, 2)
  - [ ] Verify Caddy container is running and healthy: `docker compose ps caddy | grep "healthy"`
  - [ ] Verify SeaweedFS container is running and healthy (Story 5.1 dependency)
  - [ ] Review all Docker volumes that require backup:
    - PostgreSQL: `borgstack_postgresql_data` (n8n_db, chatwoot_db, directus_db, evolution_db)
    - MongoDB: `borgstack_mongodb_data` (lowcoder)
    - Redis: `borgstack_redis_data` (AOF/RDB persistence)
    - SeaweedFS: `borgstack_seaweedfs_master`, `borgstack_seaweedfs_volume`, `borgstack_seaweedfs_filer`
    - n8n: `borgstack_n8n_data` (workflows and credentials)
    - Evolution API: `borgstack_evolution_instances` (WhatsApp sessions)
    - Caddy: `borgstack_caddy_data` (SSL certificates)
  - [ ] Review backup workflow from architecture: [Source: architecture/core-workflows.md#workflow-3-automated-backup-process]
  - [ ] **CHECKPOINT:** Confirm all prerequisites met before proceeding

- [ ] **Task 1: Add Duplicati Service to docker-compose.yml** (AC: 1)
  - [ ] Add Duplicati service definition using `duplicati/duplicati:2.1.1.102` image
  - [ ] Configure service on both networks:
    - `borgstack_internal` for volume access to all services
    - `borgstack_external` for Caddy reverse proxy access to web UI
  - [ ] Mount all critical Docker volumes for backup access (read-only for safety):
    - `/var/lib/docker/volumes/borgstack_postgresql_data/_data:/source/postgresql:ro`
    - `/var/lib/docker/volumes/borgstack_mongodb_data/_data:/source/mongodb:ro`
    - `/var/lib/docker/volumes/borgstack_redis_data/_data:/source/redis:ro`
    - `/var/lib/docker/volumes/borgstack_seaweedfs_master/_data:/source/seaweedfs_master:ro`
    - `/var/lib/docker/volumes/borgstack_seaweedfs_volume/_data:/source/seaweedfs_volume:ro`
    - `/var/lib/docker/volumes/borgstack_seaweedfs_filer/_data:/source/seaweedfs_filer:ro`
    - `/var/lib/docker/volumes/borgstack_n8n_data/_data:/source/n8n:ro`
    - `/var/lib/docker/volumes/borgstack_evolution_instances/_data:/source/evolution:ro`
    - `/var/lib/docker/volumes/borgstack_caddy_data/_data:/source/caddy:ro`
  - [ ] Mount persistent volume for Duplicati configuration:
    - `borgstack_duplicati_config:/config`
  - [ ] Expose internal port 8200 for web UI access
  - [ ] Set restart policy: `unless-stopped`
  - [ ] Configure container name: `duplicati`
  - [ ] Add dependency on PostgreSQL, MongoDB, Redis, SeaweedFS (must be healthy before backup starts)

- [ ] **Task 2: Configure Duplicati Environment Variables** (AC: 1, 4)
  - [ ] Set `DUPLICATI__WEBSERVICE_PASSWORD=${DUPLICATI_PASSWORD}` for web UI authentication
  - [ ] Set `DUPLICATI__SERVER_ENCRYPTION_PASSWORD=${DUPLICATI_ENCRYPTION_KEY}` for backup encryption
  - [ ] Set `PUID=0` and `PGID=0` (root) to access all Docker volumes
    - CRITICAL: Duplicati must run as root to access volume mount points
  - [ ] Set timezone: `TZ=America/Sao_Paulo` (Brazilian timezone for backup schedules)

- [ ] **Task 3: Implement Duplicati Health Check** (AC: 1)
  - [ ] Add health check using `curl -f http://localhost:8200 || exit 1`
  - [ ] Verify web UI responds successfully
  - [ ] Set health check interval to 30 seconds
  - [ ] Set timeout to 10 seconds
  - [ ] Set retries to 3 before marking unhealthy
  - [ ] Set start_period to 30 seconds (service initialization)

- [ ] **Task 4: Update .env.example with Duplicati Variables** (AC: 1, 4)
  - [ ] Add "Duplicati Backup System" section
  - [ ] Add `DUPLICATI_PASSWORD=<generate-random-32-char>` with generation instructions
  - [ ] Add `DUPLICATI_ENCRYPTION_KEY=<generate-random-64-char>` with generation instructions
  - [ ] Add `DUPLICATI_PASSPHRASE=<user-provided>` with note about secure storage requirement
  - [ ] Add note: "CRITICAL: Store DUPLICATI_PASSPHRASE in secure location (password manager). Without it, backups cannot be restored!"
  - [ ] Add note: "Duplicati web UI will be available at https://duplicati.${BORGSTACK_DOMAIN}"

- [ ] **Task 5: Create Duplicati Configuration Directory** (AC: 2, 3, 4, 5, 6)
  - [ ] Create `config/duplicati/` directory
  - [ ] Create `config/duplicati/README.md` with comprehensive setup instructions
  - [ ] Document backup strategy:
    - Incremental backups (only changed data after initial full backup)
    - Retention policy example: 7 daily, 4 weekly, 12 monthly
    - Encryption: AES-256 before upload
    - Compression: zstd for optimal speed/ratio
  - [ ] Document supported backup destinations (AC: 3):
    - AWS S3 / S3-compatible (recommended)
    - Google Cloud Storage
    - Backblaze B2 (cost-effective)
    - Azure Blob Storage
    - FTP/SFTP servers
    - WebDAV (Nextcloud, ownCloud)
    - Local/Network drives
  - [ ] Document backup sources to configure (AC: 2):
    - `/source/postgresql` - All PostgreSQL databases
    - `/source/mongodb` - Lowcoder database
    - `/source/redis` - Redis persistence files
    - `/source/seaweedfs_*` - SeaweedFS data
    - `/source/n8n` - Workflows and credentials
    - `/source/evolution` - WhatsApp sessions
    - `/source/caddy` - SSL certificates
  - [ ] Create `config/duplicati/backup-config-example.json` with template job definition
  - [ ] Include Brazilian data sovereignty considerations

- [ ] **Task 6: Create Backup Verification Test Script** (AC: 5, 7, 8)
  - [ ] Create `tests/deployment/verify-duplicati.sh` executable script
  - [ ] Test 1: Verify Duplicati container running and healthy
  - [ ] Test 2: Verify correct Docker image version (2.1.1.102)
  - [ ] Test 3: Verify web UI accessible on port 8200
  - [ ] Test 4: Verify all source volumes are mounted and accessible
  - [ ] Test 5: Verify Duplicati configuration volume is writeable
  - [ ] Test 6: Test backup job creation via CLI
  - [ ] Test 7: Test backup execution and file upload
  - [ ] Test 8: Test backup verification (checksum validation)
  - [ ] Test 9: Test restore functionality (AC: 7 - full restore test)
  - [ ] Test 10: Measure restore time and establish benchmarks (AC: 8)
  - [ ] Test 11: Verify AES-256 encryption is enabled (AC: 4)
  - [ ] Test 12: Verify compression is working (AC: 4)
  - [ ] Add chmod +x permission to script

- [ ] **Task 7: Update Caddy Reverse Proxy Configuration** (AC: 1)
  - [ ] Add Duplicati subdomain routing to `config/caddy/Caddyfile`:
    ```
    duplicati.{$BORGSTACK_DOMAIN} {
        reverse_proxy duplicati:8200
        encode gzip
    }
    ```
  - [ ] Verify HTTPS automatic SSL configuration
  - [ ] Add security headers for web UI protection

- [ ] **Task 8: Create Backup Documentation** (AC: 2, 3, 5, 6)
  - [ ] Create `docs/03-services/duplicati.md` (Portuguese user guide)
  - [ ] Document backup configuration steps via web UI
  - [ ] Document recommended backup schedule (e.g., daily at 2 AM)
  - [ ] Document retention policy configuration
  - [ ] Document encryption passphrase setup (AC: 4)
  - [ ] Document external storage destination setup (AC: 3)
  - [ ] Document backup verification procedures (AC: 5)
  - [ ] Document restoration procedures step-by-step (AC: 6)
  - [ ] Document disaster recovery workflow (complete system restore)
  - [ ] Include backup monitoring and alerting recommendations
  - [ ] Document Brazilian backup providers (Backblaze B2, AWS São Paulo region)

- [ ] **Task 9: Create Restoration Procedure Documentation** (AC: 6, 7)
  - [ ] Create `docs/04-integrations/backup-strategy.md` (Portuguese)
  - [ ] Document full disaster recovery scenario
  - [ ] Document partial restoration (single service)
  - [ ] Document database restoration from pg_dump/mongodump
  - [ ] Document volume restoration from file backups
  - [ ] Document testing restoration procedures (AC: 7)
  - [ ] Include step-by-step restoration test workflow
  - [ ] Document restore time expectations (AC: 8)
  - [ ] Include rollback procedures if restore fails

- [ ] **Task 10: Create Backup Automation Scripts** (AC: 3, 5)
  - [ ] Create `scripts/backup-now.sh` (manual backup trigger)
  - [ ] Create `scripts/restore.sh` (interactive restoration script)
  - [ ] Add backup pre-checks (verify services healthy, disk space available)
  - [ ] Add backup post-checks (verify backup completed, verify checksums)
  - [ ] Add notification capability (email/webhook on backup completion/failure)
  - [ ] Add chmod +x permissions to all scripts
  - [ ] Test manual backup execution

- [ ] **Task 11: Create Backup Job Configuration Template** (AC: 2, 3, 4)
  - [ ] Create `config/duplicati/backup-job-template.json`
  - [ ] Configure backup sources (all volumes from Task 5)
  - [ ] Configure encryption settings (AES-256 with passphrase)
  - [ ] Configure compression settings (zstd)
  - [ ] Configure retention policy (7 daily, 4 weekly, 12 monthly)
  - [ ] Configure backup schedule (daily at 2 AM UTC-3)
  - [ ] Add placeholders for backup destination credentials
  - [ ] Include backup verification options

- [ ] **Task 12: Add CI Workflow Validation** (AC: 1, 2)
  - [ ] Add `validate-duplicati` job to `.github/workflows/ci.yml`
  - [ ] Validate docker-compose.yml configuration for Duplicati service
  - [ ] Verify Duplicati image version pinning (2.1.1.102)
  - [ ] Verify all volume mounts are correctly defined
  - [ ] Verify environment variables are properly referenced from .env
  - [ ] Run static configuration checks
  - [ ] Execute `tests/deployment/verify-duplicati.sh` (configuration tests only)

- [ ] **Task 13: Document Restore Time Benchmarks** (AC: 8)
  - [ ] Create `docs/04-integrations/restore-benchmarks.md`
  - [ ] Document expected restore times for different scenarios:
    - Single database restore (PostgreSQL/MongoDB)
    - Single service volume restore
    - Full system restore
  - [ ] Document factors affecting restore time:
    - Backup destination bandwidth
    - Data deduplication efficiency
    - Local disk I/O speed
  - [ ] Establish baseline benchmarks on reference hardware:
    - PostgreSQL restore (1GB database): Target < 5 minutes
    - Full system restore (100GB): Target < 2 hours
  - [ ] Document restore testing schedule (monthly validation)

## Dev Notes

### Previous Story Insights

**From Story 5.1 (SeaweedFS):**
[Source: docs/stories/5.1.seaweedfs-object-storage.md#dev-agent-record]

- **Network Security Pattern**: Keep infrastructure services on `borgstack_internal` network only. Only expose via Caddy reverse proxy when web UI access is required. Duplicati requires both networks: internal for volume access, external for Caddy routing.
- **Volume Naming Convention**: All volumes follow `borgstack_{service}_{purpose}` pattern. Must be consistently applied for Duplicati volume.
- **Health Check Pattern**: Use simple curl checks with 30s interval, 10s timeout, 3-5 retries. Standard pattern works well for web UI services.
- **Unified Server Mode Success**: SeaweedFS single-container deployment pattern worked well. Duplicati also uses single-container pattern (all backup functionality in one image).
- **CI/CD Integration**: Adding validation jobs to `.github/workflows/ci.yml` ensures configuration quality. Must add `validate-duplicati` job following same pattern.
- **Backup Integration Point**: Story 5.2 (this story) will backup all three SeaweedFS volumes created in Story 5.1 (`master`, `volume`, `filer`).

### Data Models

**Volumes to Backup:**
[Source: architecture/database-schema.md, architecture/components.md]

**PostgreSQL Databases:**
- `n8n_db` - Workflow definitions, credentials, execution history
- `chatwoot_db` - Conversations, contacts, agent data
- `directus_db` - CMS content models, collections, users
- `evolution_db` - WhatsApp instance configurations, message history

**MongoDB Databases:**
- `lowcoder` - Application metadata, configurations

**Redis Data:**
- Session management data
- Background job queues
- Cache data (ephemeral, but helpful for restore)

**SeaweedFS Storage:**
[Source: architecture/components.md#seaweedfs]
- Master metadata (`borgstack_seaweedfs_master`)
- Actual file storage (`borgstack_seaweedfs_volume`)
- Filer database (`borgstack_seaweedfs_filer`)

**Application Data:**
- n8n workflows and credentials (`borgstack_n8n_data`)
- Evolution API WhatsApp sessions (`borgstack_evolution_instances`)
- Caddy SSL certificates (`borgstack_caddy_data`)

### Component Specifications

**Duplicati Service:**
[Source: architecture/components.md#duplicati-backup-system, architecture/backend-architecture.md]

**Technology Stack:**
- Image: `duplicati/duplicati:2.1.1.102` (exact version pinning required)
- Backend: .NET + Nancy Framework
- API: REST API for backup job management
- Web UI: Angular (port 8200)
- Volume: `borgstack_duplicati_config` for backup job definitions

**Key Interfaces:**
- Web UI (port 8200) exposed via Caddy reverse proxy
- Backup job scheduler (internal)
- External storage connectors (S3, FTP, WebDAV, etc.)

**Dependencies:**
- Must access all Docker volumes for backup (requires read access)
- Depends on PostgreSQL, MongoDB, Redis, SeaweedFS being healthy

### File Locations

**Docker Compose Configuration:**
[Source: architecture/unified-project-structure.md]
- `docker-compose.yml` - Add Duplicati service definition

**Configuration Files:**
```
config/duplicati/
├── README.md                      # Setup and usage instructions
├── backup-config-example.json     # Example backup job definition
└── backup-job-template.json       # Configured backup template
```

**Scripts:**
```
scripts/
├── backup-now.sh                  # Manual backup trigger
└── restore.sh                     # Interactive restoration script
```

**Documentation:**
```
docs/03-services/duplicati.md              # Portuguese user guide
docs/04-integrations/backup-strategy.md    # Backup strategy documentation
docs/04-integrations/restore-benchmarks.md # Restore time benchmarks
```

**Tests:**
```
tests/deployment/verify-duplicati.sh       # 12-test deployment validation
```

**CI/CD:**
```
.github/workflows/ci.yml                   # Add validate-duplicati job
```

### API Specifications

**Duplicati REST API:**
[Source: architecture/api-specification.md, architecture/external-apis.md]

- **Documentation:** https://duplicati.readthedocs.io/
- **Base URL:** `http://duplicati:8200` (internal) or `https://duplicati.${BORGSTACK_DOMAIN}` (external via Caddy)
- **Authentication:** Web UI password via `DUPLICATI__WEBSERVICE_PASSWORD` environment variable
- **Key Endpoints:**
  - `/api/v1/backups` - Backup job management
  - `/api/v1/backup/{id}/run` - Trigger backup execution
  - `/api/v1/backup/{id}/restore` - Restore from backup

**External Storage Providers:**
[Source: architecture/external-apis.md#external-storage-providers-via-duplicati]

**Supported Destinations:**
- AWS S3 / S3-compatible - `https://{bucket}.s3.{region}.amazonaws.com`
- Google Cloud Storage - `https://storage.googleapis.com`
- Backblaze B2 - `https://api.backblazeb2.com` (cost-effective, recommended)
- Azure Blob Storage - `https://{account}.blob.core.windows.net`
- FTP/SFTP servers - Customer-provided
- WebDAV - Customer-provided (Nextcloud, ownCloud)
- Local/Network drives - Direct file system access

**Authentication:** Provider-specific (API keys, OAuth, credentials)

**Brazilian Data Sovereignty Considerations:**
[Source: architecture/external-apis.md#external-storage-providers-via-duplicati]
- Recommended: Backblaze B2 or AWS S3 São Paulo region
- Encryption before upload ensures data security regardless of provider location

### Backup Workflow

**Automated Backup Process:**
[Source: architecture/core-workflows.md#workflow-3-automated-backup-process]

**Backup Phases:**
1. **Pre-backup Phase:**
   - Check last backup timestamp
   - Calculate incremental changes

2. **Database Dumps:**
   - PostgreSQL: `pg_dump` for n8n_db, chatwoot_db, directus_db, evolution_db
   - MongoDB: `mongodump --db lowcoder`

3. **Volume Snapshots:**
   - Read all Docker volume mount points (`/source/*`)

4. **Compression & Encryption:**
   - Compress backup data (zstd compression)
   - Encrypt with AES-256 (passphrase from DUPLICATI_PASSPHRASE)
   - Create backup metadata (timestamp, file list, checksums)

5. **Upload Phase:**
   - Upload encrypted backup chunks to external storage
   - Upload backup manifest

6. **Post-backup Phase:**
   - Verify backup integrity (compare checksums)
   - Update backup history
   - Prune old backups per retention policy (7 daily, 4 weekly, 12 monthly)
   - Send notification (success/failure)

**Backup Strategy Details:**
- **Incremental backups**: Only changed data backed up after initial full backup
- **Encryption**: AES-256 before upload to external storage
- **Retention**: 7 daily + 4 weekly + 12 monthly (configurable)
- **Schedule**: Daily at 2 AM BRT (America/Sao_Paulo timezone)
- **Deduplication**: Built-in chunk-level deduplication reduces storage costs

### Testing Requirements

**Testing Philosophy:**
[Source: architecture/testing-strategy.md]

BorgStack focuses on deployment validation and integration verification, not unit tests (pre-built Docker images).

**Test Coverage:**

**Integration Tests (Task 6):**
1. ✅ Container running and healthy
2. ✅ Correct image version (2.1.1.102)
3. ✅ Web UI accessible
4. ✅ All source volumes mounted and accessible
5. ✅ Configuration volume writeable
6. ✅ Backup job creation via CLI
7. ✅ Backup execution and upload
8. ✅ Backup verification (checksums)
9. ✅ Restore functionality (AC: 7 - full restore test)
10. ✅ Restore time benchmarks (AC: 8)
11. ✅ AES-256 encryption enabled (AC: 4)
12. ✅ Compression working (AC: 4)

**Deployment Validation Tests (Task 12):**
- Docker Compose configuration syntax validation
- Environment variable references correct
- Volume mount paths exist and accessible
- Image version pinning verified
- Network configuration correct (both internal and external)

**CI/CD Integration:**
- Add `validate-duplicati` job to `.github/workflows/ci.yml`
- Execute configuration checks on every commit
- Run deployment verification tests (configuration-only)

### Security Considerations

**Encryption at Rest and in Transit:**
[Source: architecture/security-and-performance.md]

**Mandatory (MVP):**
- ✅ **Duplicati backups**: AES-256 encryption before upload to external storage
  ```bash
  # Configured in Duplicati web UI
  Encryption: AES-256
  Passphrase: ${DUPLICATI_PASSPHRASE} from .env
  Encryption before upload: Yes
  ```
- ✅ **.env file security**: 600 permissions, excluded from git
- ✅ **Passphrase storage**: CRITICAL warning about storing passphrase securely (password manager)

**Volume Mount Security:**
- All volume mounts are read-only (`:ro` flag) for safety
- Duplicati runs as root (PUID=0, PGID=0) to access Docker volumes
- CRITICAL: This is required for backup functionality but should be documented as security consideration

**Web UI Security:**
- Password protection via `DUPLICATI__WEBSERVICE_PASSWORD`
- HTTPS access only via Caddy reverse proxy
- No direct host port exposure

### Coding Standards Compliance

**Volume Naming:**
[Source: architecture/coding-standards.md#naming-conventions]
- ✅ `borgstack_duplicati_config` (follows `borgstack_` prefix)

**Network Configuration:**
[Source: architecture/coding-standards.md#critical-infrastructure-rules]
- ✅ Duplicati on `borgstack_internal` for volume access
- ✅ Duplicati on `borgstack_external` for Caddy reverse proxy
- ✅ No ports exposed to host (access via Caddy HTTPS)

**Version Pinning:**
[Source: architecture/coding-standards.md#critical-infrastructure-rules]
- ✅ Exact image version: `duplicati/duplicati:2.1.1.102`
- ❌ Never use `latest` tag

**Health Check Requirements:**
[Source: architecture/coding-standards.md#critical-infrastructure-rules]
- ✅ Health check using web UI: `curl -f http://localhost:8200 || exit 1`
- ✅ Interval: 30s, Timeout: 10s, Retries: 3, Start period: 30s

**Dependency Management:**
[Source: architecture/coding-standards.md#critical-infrastructure-rules]
- ✅ Use `depends_on` with `condition: service_healthy` for proper startup sequencing
- Depends on: PostgreSQL, MongoDB, Redis, SeaweedFS (all must be healthy before Duplicati starts)

**Backup Before Updates:**
[Source: architecture/coding-standards.md#critical-infrastructure-rules]
- This story ENABLES the backup capability for the entire system
- After this story, all updates should run `./scripts/backup-now.sh` before changes

### Performance Considerations

**Restore Time Benchmarks:**
[Source: Epic 5.2 AC: 8]

Target benchmarks on reference hardware (36GB RAM, 8 vCPU server):

| Scenario | Target Time | Acceptable Time | Critical Threshold |
|----------|-------------|-----------------|-------------------|
| Single PostgreSQL DB (1GB) | < 5 min | < 10 min | > 30 min |
| Single service volume | < 10 min | < 20 min | > 60 min |
| Full system restore (100GB) | < 2 hours | < 4 hours | > 8 hours |

**Factors Affecting Performance:**
- Backup destination bandwidth (download speed)
- Data deduplication efficiency
- Local disk I/O speed (SSD recommended)
- Encryption/decryption overhead (AES-256)
- Compression algorithm (zstd balance of speed/ratio)

**Optimization Tips:**
- Use SSD storage for restore operations
- Ensure adequate network bandwidth to backup destination
- Schedule backups during low-traffic periods
- Monitor deduplication ratio (higher = faster backups)

### Project Structure Alignment

**No Conflicts Detected:**

All file paths and directory structures align with defined project structure:
- Configuration files in `config/duplicati/`
- Documentation in `docs/03-services/` and `docs/04-integrations/`
- Scripts in `scripts/`
- Tests in `tests/deployment/`

## Testing

### Test File Location
[Source: architecture/unified-project-structure.md]

```
tests/deployment/verify-duplicati.sh
```

### Test Standards
[Source: architecture/testing-strategy.md]

**Testing Philosophy:**
- Focus on deployment validation and integration verification
- No unit tests (pre-built Docker image)
- Verify all acceptance criteria through automated tests

**Test Execution:**
```bash
# Make test executable
chmod +x tests/deployment/verify-duplicati.sh

# Run deployment verification
./tests/deployment/verify-duplicati.sh
```

**Expected Output:**
```
========================================
Duplicati Deployment Verification
========================================
Test 1/12: Container running and healthy... PASS
Test 2/12: Correct image version... PASS
Test 3/12: Web UI accessible... PASS
Test 4/12: All source volumes mounted... PASS
Test 5/12: Configuration volume writeable... PASS
Test 6/12: Backup job creation... PASS
Test 7/12: Backup execution... PASS
Test 8/12: Backup verification... PASS
Test 9/12: Restore functionality... PASS
Test 10/12: Restore time benchmark... PASS
Test 11/12: AES-256 encryption enabled... PASS
Test 12/12: Compression working... PASS
========================================
All tests passed! Duplicati is ready.
========================================
```

### Testing Frameworks and Patterns
[Source: architecture/testing-strategy.md]

**Bash Testing Framework:**
- Use standard bash test patterns
- Each test outputs PASS/FAIL with descriptive messages
- Exit code 0 = all tests pass, Exit code 1 = at least one test failed
- Test independence (each test can run standalone)

**Integration Test Pattern:**
```bash
# Test 1: Container health
if docker compose ps duplicati | grep -q "healthy"; then
  echo "✅ Test 1: Container running and healthy... PASS"
else
  echo "❌ Test 1: Container running and healthy... FAIL"
  exit 1
fi

# Test 2: Image version
EXPECTED_VERSION="2.1.1.102"
ACTUAL_VERSION=$(docker compose images duplicati | grep duplicati | awk '{print $2}')
if [ "$ACTUAL_VERSION" = "$EXPECTED_VERSION" ]; then
  echo "✅ Test 2: Correct image version... PASS"
else
  echo "❌ Test 2: Expected $EXPECTED_VERSION, got $ACTUAL_VERSION... FAIL"
  exit 1
fi
```

### Specific Testing Requirements for This Story

**AC: 5 - Backup Verification:**
- Must test backup integrity using checksums
- Verify backup metadata matches uploaded chunks
- Test Duplicati's built-in verification feature

**AC: 6 - Restoration Procedure:**
- Document step-by-step restoration process
- Test restoration on non-production data first
- Verify all restored data matches original

**AC: 7 - Full Restore Test:**
- Perform actual full system restore from backup
- Verify all services start correctly after restore
- Confirm all data integrity (databases, files, configurations)

**AC: 8 - Restore Time Benchmarks:**
- Measure and document actual restore times
- Establish baselines for different scenarios
- Document factors affecting restore performance

**CI/CD Validation:**
- Add `validate-duplicati` job to `.github/workflows/ci.yml`
- Run configuration checks on every commit
- Execute deployment verification tests (config-only, not full backup/restore)

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-06 | 1.0 | Initial story creation | Bob (Scrum Master) |

## Dev Agent Record

*This section will be populated by the development agent during implementation.*

### Agent Model Used

*To be filled during implementation*

### Debug Log References

*To be filled during implementation*

### Completion Notes List

*To be filled during implementation*

### File List

*To be filled during implementation*

## QA Results

*This section will be populated by the QA agent after story completion.*
