# Story 4.1: Directus Headless CMS

## Status
Approved

## Story
**As a** content manager,
**I want** Directus 11 deployed with proper configuration,
**so that** I can manage and deliver content across all applications.

## Acceptance Criteria
1. Directus container running with specified version
2. Database connection to PostgreSQL working
3. Redis connection for caching configured
4. Admin user and role management setup
5. Content models and collections configured
6. API endpoints accessible for applications

## Tasks / Subtasks

- [ ] **Task 0: Verify Prerequisite Services** (AC: 2, 3)
  - [ ] Verify PostgreSQL container is running and healthy: `docker compose ps postgresql | grep "healthy"`
  - [ ] Verify Redis container is running and healthy: `docker compose ps redis | grep "healthy"`
  - [ ] Verify `directus_db` database exists in PostgreSQL: `docker compose exec postgresql psql -U postgres -lqt | grep -q directus_db`
  - [ ] Verify `directus_user` exists in PostgreSQL: `docker compose exec postgresql psql -U postgres -c "\du" | grep -q directus_user`
  - [ ] Verify `config/caddy/Caddyfile` exists and is configured from Story 1.5
  - [ ] Verify `scripts/bootstrap.sh` exists for credential generation
  - [ ] If any prerequisite is missing, HALT and notify user to complete prerequisite stories first

- [ ] **Task 1: Add Directus Service to docker-compose.yml** (AC: 1, 2, 3)
  - [ ] Add Directus service definition using `directus/directus:11` image
  - [ ] Configure Directus on both `borgstack_internal` and `borgstack_external` networks
  - [ ] Mount persistent volume `borgstack_directus_uploads` for file storage
  - [ ] Set database connection environment variables (DB_CLIENT, DB_HOST, DB_PORT, DB_DATABASE, DB_USER, DB_PASSWORD)
  - [ ] Set Redis connection environment variables (REDIS_HOST, REDIS_PORT, REDIS_PASSWORD)
  - [ ] Configure local storage (STORAGE_LOCATIONS=local) - S3 migration planned for Story 5.1
  - [ ] Set admin user credentials (ADMIN_EMAIL, ADMIN_PASSWORD)
  - [ ] Set Directus secrets (KEY, SECRET)
  - [ ] Add restart policy: `unless-stopped`
  - [ ] Configure container name: `directus`
  - [ ] Add dependency on `postgresql` (condition: service_healthy)
  - [ ] Add dependency on `redis` (condition: service_healthy)

- [ ] **Task 2: Configure Directus Environment Variables** (AC: 1, 2, 3, 6)
  - [ ] Set DB_CLIENT to `pg` (PostgreSQL driver)
  - [ ] Set DB_HOST to `postgresql`
  - [ ] Set DB_PORT to `5432`
  - [ ] Set DB_DATABASE to `directus_db`
  - [ ] Set DB_USER to `directus_user`
  - [ ] Set DB_PASSWORD from .env variable `${DIRECTUS_DB_PASSWORD}`
  - [ ] Set REDIS_HOST to `redis`
  - [ ] Set REDIS_PORT to `6379`
  - [ ] Set REDIS_PASSWORD from .env variable `${REDIS_PASSWORD}`
  - [ ] Set CACHE_ENABLED to `true`
  - [ ] Set CACHE_STORE to `redis`
  - [ ] Set CACHE_TTL to `300` (5 minutes default)
  - [ ] Set KEY from .env variable `${DIRECTUS_KEY}` (instance identifier - UUID)
  - [ ] Set SECRET from .env variable `${DIRECTUS_SECRET}` (auth token secret - 32+ chars)
  - [ ] Set ADMIN_EMAIL from .env variable `${DIRECTUS_ADMIN_EMAIL}`
  - [ ] Set ADMIN_PASSWORD from .env variable `${DIRECTUS_ADMIN_PASSWORD}`
  - [ ] Set PUBLIC_URL to `https://${DIRECTUS_HOST}`
  - [ ] Set WEBSOCKETS_ENABLED to `true`

- [ ] **Task 3: Configure Directus Local Storage (Temporary until Story 5.1)** (AC: 1)
  - [ ] Set STORAGE_LOCATIONS to `local` (will migrate to SeaweedFS S3 in Story 5.1)
  - [ ] Configure local storage to use `/directus/uploads` directory
  - [ ] Ensure `borgstack_directus_uploads` volume is properly mounted
  - [ ] Add TODO comment in docker-compose.yml: "MIGRATION: Switch to SeaweedFS S3 storage in Story 5.1"
  - [ ] Document S3 migration plan in config/directus/README.md under "Future Enhancements" section
  - [ ] Prepare S3 configuration template in config/directus/s3-storage.env.example for Story 5.1:
    - STORAGE_LOCATIONS=seaweedfs
    - STORAGE_SEAWEEDFS_DRIVER=s3
    - STORAGE_SEAWEEDFS_ENDPOINT=http://seaweedfs:8333
    - STORAGE_SEAWEEDFS_BUCKET=borgstack
    - STORAGE_SEAWEEDFS_ROOT=directus/

- [ ] **Task 4: Implement Directus Health Check** (AC: 1)
  - [ ] Add health check using `wget --no-verbose --tries=1 --spider http://localhost:8055/server/health || exit 1`
  - [ ] Set health check interval to 30 seconds
  - [ ] Set timeout to 10 seconds
  - [ ] Set retries to 5 before marking unhealthy
  - [ ] Set start_period to 60 seconds (database migrations + initialization)

- [ ] **Task 5: Update .env.example with Directus Variables** (AC: 1, 2, 3, 4)
  - [ ] Add `DIRECTUS_HOST=directus.${BORGSTACK_DOMAIN}` variable
  - [ ] Add `DIRECTUS_DB_PASSWORD=<generate-strong-password>` placeholder
  - [ ] Add `DIRECTUS_KEY=<generate-uuid>` placeholder with comment "Use: uuidgen or openssl rand -hex 16"
  - [ ] Add `DIRECTUS_SECRET=<generate-secret>` placeholder with comment "Use: openssl rand -base64 32"
  - [ ] Add `DIRECTUS_ADMIN_EMAIL=admin@${BORGSTACK_DOMAIN}` default value
  - [ ] Add `DIRECTUS_ADMIN_PASSWORD=<generate-strong-password>` placeholder
  - [ ] Add comment section: "Directus Headless CMS Configuration"
  - [ ] Add security warning: "DIRECTUS_SECRET protects authentication tokens - keep secure"
  - [ ] Add note: "DIRECTUS_KEY is instance identifier - must be unique UUID"
  - [ ] Add note: "File storage uses local volumes initially - S3 migration in Story 5.1"

- [ ] **Task 6: Verify Directus Caddy Configuration** (AC: 6)
  - [ ] Verify reverse proxy block for `${DIRECTUS_HOST}` exists in `config/caddy/Caddyfile`
  - [ ] Verify proxy target is set to `http://directus:8055`
  - [ ] Verify WebSocket support is enabled for real-time updates
  - [ ] Verify security headers are configured (CORS, CSP)
  - [ ] Verify automatic HTTPS via Let's Encrypt is enabled
  - [ ] Confirm configuration matches Story 1.5 Caddy setup

- [ ] **Task 7: Verify PostgreSQL Database Configuration** (AC: 2)
  - [ ] Verify directus_db database creation in `config/postgresql/init-databases.sql`
  - [ ] Verify directus_user creation with password from `${DIRECTUS_DB_PASSWORD}`
  - [ ] Verify ALL PRIVILEGES granted on directus_db to directus_user
  - [ ] Verify directus_user set as owner of directus_db
  - [ ] Verify pgvector extension enabled in directus_db for potential vector search features

- [ ] **Task 8: Add Directus Credentials Generation to scripts/bootstrap.sh** (AC: 4)
  - [ ] Add DIRECTUS_DB_PASSWORD generation using `openssl rand -base64 32 | tr -d "=+/" | cut -c1-32`
  - [ ] Add DIRECTUS_KEY generation using `uuidgen` or `openssl rand -hex 16`
  - [ ] Add DIRECTUS_SECRET generation using `openssl rand -base64 32`
  - [ ] Add DIRECTUS_ADMIN_PASSWORD generation using `openssl rand -base64 24 | tr -d "=+/" | cut -c1-24`
  - [ ] Set DIRECTUS_ADMIN_EMAIL from user input or default to `admin@${BORGSTACK_DOMAIN}`
  - [ ] Ensure all secrets are written to .env file during bootstrap
  - [ ] Add Directus credentials to credential summary display
  - [ ] Add completion message with Directus URL and admin credentials

- [ ] **Task 9: Create Directus Configuration Documentation** (AC: 4, 5, 6)
  - [ ] Create `config/directus/README.md` with setup instructions
  - [ ] Document first-time admin login process
  - [ ] Document how to create content collections and fields
  - [ ] Document REST API endpoint format: `https://directus.${BORGSTACK_DOMAIN}/items/{collection}`
  - [ ] Document GraphQL endpoint: `https://directus.${BORGSTACK_DOMAIN}/graphql`
  - [ ] Document current local file storage configuration
  - [ ] Add "Future Enhancements" section documenting S3 migration planned for Story 5.1
  - [ ] Document role and permission management
  - [ ] Document API token generation for programmatic access
  - [ ] Add troubleshooting section for common issues (DB connection, file storage, cache)

- [ ] **Task 10: Create Directus Deployment Verification Test** (AC: 1, 2, 3, 6)
  - [ ] Create `tests/deployment/verify-directus.sh` test script
  - [ ] Test 1: Verify Directus container is running: `docker compose ps directus | grep -q "Up"`
  - [ ] Test 2: Verify correct image version: `docker compose ps directus | grep -q "directus/directus:11"`
  - [ ] Test 3: Verify health check is passing: `docker compose ps directus | grep -q "healthy"`
  - [ ] Test 4: Verify database connection by checking logs for successful migration
  - [ ] Test 5: Verify Redis connection by checking cache initialization in logs
  - [ ] Test 6: Verify local storage is configured by checking STORAGE_LOCATIONS=local in environment
  - [ ] Test 7: Verify web UI accessibility: `curl -f https://${DIRECTUS_HOST}/admin/login`
  - [ ] Test 8: Verify server health endpoint: `curl -f https://${DIRECTUS_HOST}/server/health`
  - [ ] Test 9: Verify REST API endpoint: `curl -f https://${DIRECTUS_HOST}/server/ping`
  - [ ] Test 10: Verify GraphQL introspection endpoint accessible
  - [ ] Test 11: Verify WebSocket endpoint available for real-time updates
  - [ ] Make script executable: `chmod +x tests/deployment/verify-directus.sh`

- [ ] **Task 11: Test Directus Content Management** (AC: 5)
  - [ ] Login to Directus admin UI at `https://${DIRECTUS_HOST}/admin`
  - [ ] Create test collection (e.g., "blog_posts" with title, content, author fields)
  - [ ] Create test item in collection
  - [ ] Verify item appears in REST API: `GET /items/blog_posts`
  - [ ] Test file upload to verify local storage integration
  - [ ] Verify uploaded file accessible via Directus assets endpoint
  - [ ] Verify file is stored in `borgstack_directus_uploads` volume
  - [ ] Test GraphQL query for created content
  - [ ] Document test results in story completion notes

- [ ] **Task 12: Create Basic Directus User Guide (Portuguese)** (AC: 5, 6)
  - [ ] Create `docs/03-services/directus.md` documentation file
  - [ ] Add "O que é Directus?" introduction section
  - [ ] Add "Acessando o Directus" section with login instructions
  - [ ] Add "Criando Coleções" section with step-by-step guide
  - [ ] Add "Gerenciando Conteúdo" section for CRUD operations
  - [ ] Add "Upload de Arquivos" section explaining media management
  - [ ] Add "APIs REST e GraphQL" section with examples
  - [ ] Add "Gerenciamento de Usuários e Permissões" section
  - [ ] Add "Integração com n8n" examples for workflow automation
  - [ ] Add "Solução de Problemas" troubleshooting section

- [ ] **Task 13: Run All Deployment Tests** (AC: 1-6)
  - [ ] Execute `tests/deployment/verify-directus.sh` and confirm all tests pass
  - [ ] Verify no errors in Directus container logs: `docker compose logs directus --tail=100`
  - [ ] Verify PostgreSQL connection pool shows Directus connections
  - [ ] Verify Redis shows Directus cache keys with `directus:cache:*` prefix
  - [ ] Verify local file storage in `borgstack_directus_uploads` volume contains uploaded files
  - [ ] Document any issues or deviations in story completion notes

## Dev Notes

### Architecture Context

**Service Purpose:**
Directus is a headless CMS and data management platform that provides REST and GraphQL APIs for content delivery. It uses PostgreSQL for structured data, Redis for caching, and SeaweedFS for file storage.
[Source: architecture/components.md#directus-headless-cms]

**Deployment Model:** Single container with automatic database migrations on startup
[Source: architecture/components.md#directus-headless-cms]

### Component Details

**Container Specifications:**
[Source: architecture/components.md#directus-headless-cms]
- Image: `directus/directus:11`
- Exposed Port: 8055 (Web UI + API)
- Networks: `borgstack_internal`, `borgstack_external`
- Dependencies: PostgreSQL (`directus_db`), Redis (caching), SeaweedFS (file storage via S3)

**Key Interfaces:**
- Web UI (port 8055) exposed via Caddy reverse proxy
- REST API: `https://directus.${BORGSTACK_DOMAIN}/items/{collection}`
- GraphQL API: `https://directus.${BORGSTACK_DOMAIN}/graphql`
- Asset management with SeaweedFS S3 integration

**Technology Stack:**
- Backend: Node.js + Express + Knex.js (database abstraction)
- Database Migrations: Knex.js migrations (automatic on startup)
- File Storage: S3-compatible API (SeaweedFS)

### Database Configuration

**PostgreSQL Database:**
[Source: architecture/database-schema.md#postgresql-database-organization]

```sql
CREATE DATABASE directus_db;
CREATE USER directus_user WITH ENCRYPTED PASSWORD '${DIRECTUS_DB_PASSWORD}';
GRANT ALL PRIVILEGES ON DATABASE directus_db TO directus_user;
ALTER DATABASE directus_db OWNER TO directus_user;

-- Enable pgvector extension for potential vector search features
\c directus_db
CREATE EXTENSION IF NOT EXISTS vector;
```

**Schema Management:** Automatic migrations on startup via Knex.js
[Source: architecture/database-schema.md#postgresql-database-organization]

**Performance Configuration:**
Uses shared PostgreSQL 18 instance with optimized settings for 36GB RAM server
[Source: architecture/database-schema.md#postgresql-database-organization]

### Redis Cache Configuration

**Cache Strategy:**
[Source: architecture/database-schema.md#redis-data-organization]

```
directus:cache:{collection}       # Directus collection cache
directus:session:{token}          # Directus authentication tokens
```

**Cache Settings:**
- Cache enabled: `CACHE_ENABLED=true`
- Cache store: `CACHE_STORE=redis`
- Default TTL: 300 seconds (5 minutes)

### File Storage Configuration

**Current Implementation: Local Storage**

For Story 4.1, Directus uses local volume storage:
- Storage location: `borgstack_directus_uploads` volume
- Path inside container: `/directus/uploads`
- Configuration: `STORAGE_LOCATIONS=local`

**Future Migration: SeaweedFS S3 Storage (Story 5.1)**
[Source: architecture/database-schema.md#seaweedfs-storage-organization]

Planned bucket structure after Story 5.1:
```
/borgstack/directus/
  ├── originals/      # Original uploaded files
  ├── thumbnails/     # Auto-generated thumbnails
  └── documents/      # Document assets
```

**Planned S3 Environment Variables (Story 5.1):**
- Driver: `s3`
- Endpoint: `http://seaweedfs:8333`
- Bucket: `borgstack`
- Root: `directus/` (all Directus files prefixed)
- Credentials: `${SEAWEEDFS_ACCESS_KEY}`, `${SEAWEEDFS_SECRET_KEY}`

**Migration Path:**
A configuration template will be created in `config/directus/s3-storage.env.example` for easy transition when Story 5.1 is complete.

### Environment Variables Required

**Core Configuration:**
[Source: architecture/development-workflow.md#required-environment-variables]

- `DIRECTUS_HOST=directus.${BORGSTACK_DOMAIN}` - Service hostname
- `DIRECTUS_ADMIN_EMAIL=admin@${BORGSTACK_DOMAIN}` - Initial admin user email
- `DIRECTUS_ADMIN_PASSWORD` - Initial admin user password

**Security Secrets:**
- `DIRECTUS_KEY` - Instance identifier (UUID format)
- `DIRECTUS_SECRET` - Auth token signing secret (32+ characters)
- `DIRECTUS_DB_PASSWORD` - PostgreSQL user password

**Database Connection:**
- `DB_CLIENT=pg`
- `DB_HOST=postgresql`
- `DB_PORT=5432`
- `DB_DATABASE=directus_db`
- `DB_USER=directus_user`
- `DB_PASSWORD=${DIRECTUS_DB_PASSWORD}`

**Redis Connection:**
- `REDIS_HOST=redis`
- `REDIS_PORT=6379`
- `REDIS_PASSWORD=${REDIS_PASSWORD}`

### Coding Standards

**Docker Compose Configuration:**
[Source: architecture/coding-standards.md#critical-infrastructure-rules]

1. **Version Pinning:** Use exact version `directus/directus:11` (NOT `latest`)
2. **Volume Naming:** `borgstack_directus_uploads` follows naming convention
3. **Network Isolation:** Connect to `borgstack_internal` (database, Redis, SeaweedFS) and `borgstack_external` (Caddy)
4. **Health Checks:** Required - use `/server/health` endpoint
5. **Dependency Management:** Use `depends_on` with `service_healthy` for PostgreSQL and Redis
6. **Configuration as Code:** Store Directus config in environment variables, not volumes

**Security Requirements:**
[Source: architecture/coding-standards.md#critical-infrastructure-rules]

- Never expose port 8055 to host in production (proxy via Caddy only)
- Use strong passwords (32+ characters for DB password)
- Protect DIRECTUS_SECRET (used for JWT signing)
- Use unique DIRECTUS_KEY per deployment

### Caddy Reverse Proxy Configuration

**Expected Caddyfile Entry:**
[Source: architecture/components.md#caddy]

```
{$DIRECTUS_HOST} {
    reverse_proxy directus:8055

    # WebSocket support for real-time updates
    @websockets {
        header Connection *Upgrade*
        header Upgrade websocket
    }
    reverse_proxy @websockets directus:8055
}
```

**Security Headers:** Automatic via Caddy defaults
**SSL/TLS:** Automatic via Let's Encrypt

### Project Structure

**Configuration Files:**
[Source: architecture/unified-project-structure.md]

```
borgstack/
├── config/directus/
│   └── README.md              # Directus setup documentation
├── docs/03-services/
│   └── directus.md            # Portuguese user guide
└── tests/deployment/
    └── verify-directus.sh     # Deployment validation script
```

### Testing

**Testing Philosophy:**
[Source: architecture/testing-strategy.md#testing-pyramid]

- No unit tests (Directus is pre-built)
- Focus on deployment validation
- Configuration verification
- Integration testing with PostgreSQL, Redis, SeaweedFS

**Validation Commands:**
```bash
# Validate docker-compose configuration
docker compose config | grep -A 20 "directus:"

# Test health endpoint
curl -f https://${DIRECTUS_HOST}/server/health

# Test API ping
curl -f https://${DIRECTUS_HOST}/server/ping

# Verify database connection
docker compose logs directus | grep -i "database"

# Verify S3 storage connection
docker compose logs directus | grep -i "storage"
```

**Test Script Location:** `tests/deployment/verify-directus.sh`

### Integration Points

**Directus Integration with Other Services:**
[Source: architecture/components.md#component-diagrams]

1. **PostgreSQL:** Uses `directus_db` for all content storage
2. **Redis:** Uses for caching API responses and session management
3. **Local Storage:** Uses `borgstack_directus_uploads` volume (Story 4.1) - will migrate to SeaweedFS S3 in Story 5.1
4. **Caddy:** Reverse proxy for HTTPS access
5. **n8n:** Can be integrated for workflow automation (content triggers, automated publishing)
6. **Duplicati:** Backs up Directus database and file storage

**API Access:**
[Source: architecture/api-specification.md]

- REST API Documentation: https://docs.directus.io/reference/
- GraphQL Introspection: Available at `/graphql` endpoint
- Authentication: Bearer token or session-based

### Troubleshooting Notes

**Common Issues:**

1. **Database Migration Failures:**
   - Check PostgreSQL logs: `docker compose logs postgresql`
   - Verify directus_user has proper permissions
   - Ensure `directus_db` exists and is owned by `directus_user`

2. **Local Storage Issues:**
   - Verify `borgstack_directus_uploads` volume is properly mounted
   - Check volume permissions allow Directus container to write files
   - Verify STORAGE_LOCATIONS is set to `local` in environment variables

3. **Redis Cache Not Working:**
   - Verify REDIS_PASSWORD matches Redis configuration
   - Check Redis logs for authentication errors
   - Confirm Redis is accessible from `borgstack_internal` network

4. **Admin Login Issues:**
   - Admin user created automatically on first startup
   - Verify ADMIN_EMAIL and ADMIN_PASSWORD set correctly
   - Check Directus logs for user creation confirmation

### Previous Story Context

**Related Completed Stories:**
- Story 1.3: PostgreSQL setup with `directus_db` database
- Story 1.4: Redis cache configuration (shared)
- Story 1.5: Caddy reverse proxy with automatic SSL

**Future Story Dependencies:**
- Story 5.1: SeaweedFS S3-compatible storage (Epic 5 - not yet implemented)

**Implementation Note:**
Story 4.1 implements Directus with local file storage initially. After Story 5.1 (SeaweedFS) is complete, Directus configuration will be updated to use S3-compatible storage. A configuration template (`config/directus/s3-storage.env.example`) will be created during this story to facilitate the future migration.

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-04 | 1.0 | Initial story creation for Directus Headless CMS deployment | Bob (Scrum Master) |
| 2025-10-04 | 1.1 | Story validation corrections: (1) Resolved SeaweedFS dependency by using local storage with migration plan, (2) Added Task 0 for prerequisite verification, (3) Specified explicit file paths (scripts/bootstrap.sh, config/caddy/Caddyfile), (4) Updated all tasks and Dev Notes to reflect local storage configuration | Sarah (Product Owner) |

## Dev Agent Record

### Agent Model Used
_To be filled by Dev Agent_

### Debug Log References
_To be filled by Dev Agent_

### Completion Notes
_To be filled by Dev Agent_

### File List
_To be filled by Dev Agent_

## QA Results
_To be filled by QA Agent_
