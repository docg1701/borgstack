# ============================================================================
# BorgStack - Environment Variables Template
# ============================================================================
#
# IMPORTANT: This is a template file. DO NOT commit the actual .env file!
#
# Setup Instructions:
# 1. Copy this file to .env: cp .env.example .env
# 2. Replace all placeholder values with your actual configuration
# 3. Ensure .env has restricted permissions: chmod 600 .env
# 4. Never commit .env to version control (already in .gitignore)
#
# Security Best Practices:
# - Use strong, unique passwords (minimum 32 characters recommended)
# - Use a password manager to generate secure passwords
# - Rotate credentials regularly
# - Never share credentials via email or chat
# - Use different passwords for each service
#
# ============================================================================

# ============================================================================
# PostgreSQL Database (Shared)
# ============================================================================
# PostgreSQL is the primary relational database shared by n8n, Chatwoot,
# Directus, and Evolution API. Uses pgvector extension for AI/LLM features.
#
# Version: PostgreSQL 18.0 with pgvector extension

# Master PostgreSQL admin password
# Used by the postgres superuser account
POSTGRES_PASSWORD=CHANGE_ME_TO_A_SECURE_PASSWORD_MIN_32_CHARS

# n8n database credentials
# Database name: n8n_db
N8N_DB_PASSWORD=CHANGE_ME_TO_A_SECURE_PASSWORD_MIN_32_CHARS

# Chatwoot database credentials
# Database name: chatwoot_db
CHATWOOT_DB_PASSWORD=CHANGE_ME_TO_A_SECURE_PASSWORD_MIN_32_CHARS

# Directus database credentials
# Database name: directus_db
DIRECTUS_DB_PASSWORD=CHANGE_ME_TO_A_SECURE_PASSWORD_MIN_32_CHARS

# Evolution API database credentials
# Database name: evolution_db
EVOLUTION_DB_PASSWORD=CHANGE_ME_TO_A_SECURE_PASSWORD_MIN_32_CHARS

# ============================================================================
# MongoDB Database (Lowcoder Only)
# ============================================================================
# MongoDB is used exclusively by Lowcoder for its metadata storage.
# Isolated from other services to prevent schema conflicts.
#
# Version: MongoDB 7.0
#
# Database Isolation Strategy:
#   - MongoDB dedicated exclusively to Lowcoder (no other services)
#   - Separation from PostgreSQL maintains clear service boundaries
#   - Lowcoder requires NoSQL for flexible application metadata
#
# Security:
#   - Root admin user (admin) for administrative tasks only
#   - Dedicated service user (lowcoder_user) with scoped permissions
#   - Principle of least privilege: lowcoder_user has readWrite + dbAdmin on lowcoder DB only
#
# ⚠️  SECURITY WARNING: Use strong, unique passwords (minimum 32 characters)
# Generate secure passwords with: openssl rand -base64 32 | tr -d "=+/" | cut -c1-32

# MongoDB root admin username (for administrative tasks only)
# Used by the admin user for database management
# IMPORTANT: This is used for MONGO_INITDB_ROOT_USERNAME in docker-compose.yml
MONGO_INITDB_ROOT_USERNAME=admin

# MongoDB root admin password (for administrative tasks only)
# Used by the admin user for database management
# IMPORTANT: This is used for MONGODB_ROOT_PASSWORD in docker-compose.yml
MONGODB_ROOT_PASSWORD=CHANGE_ME_TO_A_SECURE_PASSWORD_MIN_32_CHARS

# Lowcoder database user password
# Used by lowcoder_user for application database access
# This user has readWrite and dbAdmin roles on the lowcoder database only
LOWCODER_DB_PASSWORD=CHANGE_ME_TO_A_SECURE_PASSWORD_MIN_32_CHARS

# ============================================================================
# Redis Cache/Queue (Shared)
# ============================================================================
# Redis is used for session management, caching, and message queuing across
# all services. Shared to reduce infrastructure complexity.
#
# Version: Redis 8.2 (Alpine)
# Allocation: 8GB memory, optimized for 36GB RAM server
# Persistence: RDB snapshots + AOF (max 1 second data loss)
#
# Service Usage:
#   - n8n:      Session management, Bull queue processing (DB 0)
#   - Chatwoot: Session management, Sidekiq background jobs (DB 0)
#   - Lowcoder: Session storage (DB 0)
#   - Directus: Caching layer (DB 0)
#
# Connection String Formats (used automatically by service configurations):
#   Standard format: redis://:${REDIS_PASSWORD}@redis:6379
#   n8n format:      QUEUE_BULL_REDIS_HOST=redis QUEUE_BULL_REDIS_PORT=6379 QUEUE_BULL_REDIS_PASSWORD=${REDIS_PASSWORD}
#   Chatwoot format: REDIS_HOST=redis REDIS_PORT=6379 REDIS_PASSWORD=${REDIS_PASSWORD}
#   Lowcoder format: LOWCODER_REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379
#   Directus format: REDIS_HOST=redis REDIS_PORT=6379 REDIS_PASSWORD=${REDIS_PASSWORD}
#
# Security:
#   - Network isolation: Redis only accessible via borgstack_internal network
#   - Password authentication: Required for all connections
#   - No port exposure: Redis not accessible from host machine

# Redis password (minimum 32 characters recommended)
# Generate secure password: openssl rand -base64 32
# Used for all Redis operations and service connections
REDIS_PASSWORD=CHANGE_ME_TO_A_SECURE_PASSWORD_MIN_32_CHARS

# ════════════════════════════════════════════════════════════════════════════
# Caddy Reverse Proxy Configuration
# ════════════════════════════════════════════════════════════════════════════
#
# Caddy provides automatic HTTPS with Let's Encrypt for all web services.
# SSL certificates are provisioned and renewed automatically with zero configuration.
#
# Version: Caddy 2.10 (Alpine)
# Features: Automatic HTTPS, HTTP to HTTPS redirection, reverse proxy routing

# Base domain for all services
# This domain must have DNS A records pointing to your server IP
# Example: example.com.br → Generates subdomains: n8n.example.com.br, chatwoot.example.com.br, etc.
DOMAIN=example.com.br

# Email for Let's Encrypt SSL certificate notifications
# Used for certificate expiration warnings (should never happen due to auto-renewal)
# Replace with administrator email address
EMAIL=admin@example.com.br

# CORS (Cross-Origin Resource Sharing) allowed origins for API services
# Controls which domains can access Evolution API and Directus API endpoints
#
# SECURITY WARNING: The default "*" (wildcard) allows requests from ANY origin.
# This is ONLY acceptable for development/testing environments.
#
# Production Configuration (REQUIRED before production deployment):
#   - Replace "*" with specific allowed origins (comma-separated list)
#   - Examples:
#     Single origin:  https://app.example.com.br
#     Multiple:       https://app.example.com.br,https://admin.example.com.br
#     Localhost dev:  http://localhost:3000,http://localhost:8080
#
# Affected Services:
#   - Evolution API (WhatsApp Business API - Story 2.2)
#   - Directus (Headless CMS API - Story 4.1)
#
# Note: Web UI services (n8n, Chatwoot, Lowcoder, FileFlows, Duplicati) do not
# use CORS headers as they serve their own UIs directly.
CORS_ALLOWED_ORIGINS=*

# ════════════════════════════════════════════════════════════════════════════
# DNS Configuration Requirements
# ════════════════════════════════════════════════════════════════════════════
# Before deploying Caddy, create DNS A records for all subdomains:
#   n8n.example.com.br      A   YOUR_SERVER_IP
#   chatwoot.example.com.br A   YOUR_SERVER_IP
#   evolution.example.com.br A  YOUR_SERVER_IP
#   lowcoder.example.com.br A   YOUR_SERVER_IP
#   directus.example.com.br A   YOUR_SERVER_IP
#   fileflows.example.com.br A  YOUR_SERVER_IP
#   duplicati.example.com.br A  YOUR_SERVER_IP
#
# Verification Commands:
#   Verify DNS propagation: dig n8n.example.com.br +short
#   Expected output: YOUR_SERVER_IP
#
# SSL Certificate Generation:
#   - Occurs automatically on first request to each subdomain
#   - Requires port 80 accessible for ACME HTTP-01 challenge
#   - Can take 30-60 seconds per domain on first deployment
#   - Caddy retries automatically if initial attempt fails
#   - Certificates stored in borgstack_caddy_data volume
#   - Auto-renewal 30 days before expiration (no manual intervention)
#
# Firewall Requirements:
#   - Port 80 must be open (HTTP and ACME challenge)
#   - Port 443 must be open (HTTPS)
#   - Verify with: sudo ufw status (if using ufw)
# ════════════════════════════════════════════════════════════════════════════

# ============================================================================
# Service-Specific Configuration
# ============================================================================

# ----------------------------------------------------------------------------
# n8n Configuration
# ----------------------------------------------------------------------------
# Workflow automation platform configuration
#
# n8n workflow automation credentials
# ⚠️  CRITICAL SECURITY: The N8N_ENCRYPTION_KEY protects all workflow credentials
#     - NEVER share or commit this key to version control
#     - Loss of this key = loss of access to ALL encrypted workflow credentials
#     - Store securely (password manager, encrypted backup)
#     - Rotate regularly in production environments

# n8n hostname (subdomain for n8n service)
# This is automatically constructed using the base DOMAIN variable
N8N_HOST=n8n.${DOMAIN}

# n8n basic authentication (initial admin account)
# Used for HTTP Basic Auth protection before reaching n8n login
# Change these after first login via n8n web interface
N8N_BASIC_AUTH_USER=admin
N8N_BASIC_AUTH_PASSWORD=CHANGE_ME_TO_A_SECURE_PASSWORD_MIN_32_CHARS

# n8n encryption key (used for encrypting credentials in database)
# Generate with: openssl rand -base64 32
# CRITICAL: Backup this key securely - without it, encrypted credentials are lost
N8N_ENCRYPTION_KEY=CHANGE_ME_TO_A_SECURE_KEY_MIN_32_CHARS

# n8n database password (for n8n_user PostgreSQL access)
# Generate with: openssl rand -base64 32 | tr -d "=+/" | cut -c1-32
N8N_DB_PASSWORD=CHANGE_ME_TO_A_SECURE_PASSWORD_MIN_32_CHARS

# ───────────────────────────────────────────────────────────────────────────────
# n8n Storage Configuration (Story 5.3)
# ───────────────────────────────────────────────────────────────────────────────
# Using default filesystem storage (100% free, no Enterprise License required)
#
# For SeaweedFS integration: Use HTTP Request node in workflows
# Filer API endpoint: http://seaweedfs:8888/
#
# Example workflow operations:
#   Upload:   POST http://seaweedfs:8888/my-bucket/file.pdf
#   Download: GET  http://seaweedfs:8888/my-bucket/file.pdf
#   List:     GET  http://seaweedfs:8888/my-bucket/?pretty=y
#   Delete:   DELETE http://seaweedfs:8888/my-bucket/file.pdf
#
# Full documentation: docs/04-integrations/seaweedfs-filer-api-n8n.md

# ----------------------------------------------------------------------------
# Chatwoot Configuration
# ----------------------------------------------------------------------------
# Chatwoot customer service platform credentials
#
# Chatwoot is an omnichannel customer communication platform with support for
# WhatsApp (via Evolution API), web chat, and agent management.
#
# Key Features:
#   - Multi-channel support (WhatsApp, web chat, future: Instagram DM, Facebook Messenger)
#   - Agent dashboard for team collaboration
#   - Conversation tracking and assignment
#   - Integration with n8n for WhatsApp automation via Evolution API
#
# Security Architecture:
#   - Rails SECRET_KEY_BASE protects session encryption and cookies
#   - API access token required for programmatic access (n8n integration)
#   - Database isolation (chatwoot_user has access only to chatwoot_db)
#   - Network isolation (no port exposure, HTTPS via Caddy only)
#
# Integration Pattern:
#   WhatsApp → Evolution API → n8n → Chatwoot API (incoming messages)
#   Chatwoot webhook → n8n → Evolution API → WhatsApp (outgoing replies)
#
# ⚠️  CRITICAL SECURITY WARNINGS:
#   1. CHATWOOT_SECRET_KEY_BASE: Rails session and cookie encryption
#      - Must be 128-character hex string (generate with: openssl rand -hex 64)
#      - NEVER share or commit this key to version control
#      - Loss of this key = all user sessions invalidated
#      - Required for Rails application to start
#
#   2. CHATWOOT_API_TOKEN: API access for n8n integration
#      - CANNOT be auto-generated by bootstrap script
#      - Must be manually generated from Chatwoot admin UI after first login
#      - Steps: Login → Settings → Account Settings → Access Tokens → Create New Token
#      - Token permissions: Full access required for n8n integration
#      - Store securely - token grants full API access to Chatwoot
#      - Add to .env BEFORE configuring n8n workflows
#      - Restart Chatwoot after adding token: docker compose restart chatwoot
#
#   3. CHATWOOT_DB_PASSWORD: PostgreSQL database access
#      - Already configured above in PostgreSQL section (line 40)
#      - Used by Chatwoot to connect to chatwoot_db database

# Chatwoot hostname (subdomain for Chatwoot service)
# Admin UI accessible at: https://${CHATWOOT_HOST}/app
# API documentation: https://${CHATWOOT_HOST}/api/v1
CHATWOOT_HOST=chatwoot.${DOMAIN}

# Chatwoot Rails secret key base (used for session encryption and cookie signing)
# Generate with: openssl rand -hex 64
# CRITICAL: Backup this key securely - required for Rails to start
CHATWOOT_SECRET_KEY_BASE=CHANGE_ME_TO_A_128_CHARACTER_HEX_STRING

# Chatwoot API access token for n8n integration
# ⚠️  MANUAL STEP REQUIRED - This CANNOT be automated:
#   1. Deploy Chatwoot: docker compose up -d chatwoot
#   2. Wait for startup: docker compose logs -f chatwoot (watch for "Rails migrations completed")
#   3. Login to Chatwoot: https://chatwoot.${DOMAIN}/app (create admin account on first login)
#   4. Go to Settings → Account Settings → Access Tokens
#   5. Click "Create New Token" and copy the generated token
#   6. Add token to .env as CHATWOOT_API_TOKEN=<your-token-here>
#   7. Restart Chatwoot: docker compose restart chatwoot
#   8. Token is now available for n8n integration workflows
# Note: Token grants full API access - protect like a password
CHATWOOT_API_TOKEN=<obtain-from-admin-ui-after-first-login>

# ----------------------------------------------------------------------------
# Evolution API Configuration
# ----------------------------------------------------------------------------
# WhatsApp Business API gateway for multi-instance WhatsApp connectivity
#
# Evolution API is a self-hosted WhatsApp Business API gateway that enables
# WhatsApp message sending/receiving through HTTP API endpoints and webhooks.
#
# Key Features:
#   - Multi-instance support (multiple WhatsApp business accounts per server)
#   - QR code authentication (scan with WhatsApp to connect)
#   - Webhook delivery to n8n for incoming message events
#   - PostgreSQL storage for message history and instance data
#   - Redis caching for session management
#
# Security Architecture:
#   - API key authentication required for all API operations
#   - Instance-level authentication for granular access control
#   - Database isolation (evolution_user has access only to evolution_db)
#   - Network isolation (no port exposure, HTTPS via Caddy only)
#
# Integration Pattern:
#   WhatsApp → Evolution API → Webhook → n8n → Chatwoot/other services
#
# ⚠️  CRITICAL SECURITY WARNINGS:
#   1. EVOLUTION_API_KEY: Protects ALL Evolution API operations (instance creation, message sending)
#      - Use strong 32+ character key (generate with: openssl rand -base64 32)
#      - Include in apikey header for ALL API requests
#      - NEVER expose in client-side code or public repositories
#      - Rotate regularly (monthly recommended for production)
#
#   2. EVOLUTION_DB_PASSWORD: PostgreSQL database access for message history
#      - Already configured above in PostgreSQL section (line 48)
#      - Used by Evolution API to store WhatsApp messages and instance configurations
#
#   3. EVOLUTION_WEBHOOK_URL: Destination for incoming WhatsApp messages
#      - Must use HTTPS (HTTP webhooks will be rejected by Evolution API)
#      - n8n webhook endpoint must be active before Evolution API sends events

# Evolution API hostname (subdomain for Evolution API service)
# Admin UI accessible at: https://${EVOLUTION_HOST}/manager
# API documentation: https://${EVOLUTION_HOST}/docs
EVOLUTION_HOST=evolution.${DOMAIN}

# Evolution API global authentication key
# Required in "apikey" header for ALL API operations:
#   - Instance creation (POST /instance/create)
#   - Message sending (POST /message/sendText/{instanceName})
#   - Instance management (GET/DELETE /instance/{instanceName})
# Generate with: openssl rand -base64 32
# ⚠️  WARNING: Treat this key like a root password - it controls ALL WhatsApp instances
EVOLUTION_API_KEY=CHANGE_ME_TO_A_SECURE_API_KEY_MIN_32_CHARS

# Evolution API webhook URL for incoming WhatsApp messages
# Evolution API sends incoming messages to this n8n webhook endpoint
# n8n workflow receives messages and routes to Chatwoot or other services
# Format: https://{N8N_HOST}/webhook/{path}
# Must be HTTPS (Evolution API rejects HTTP webhooks for security)
EVOLUTION_WEBHOOK_URL=https://${N8N_HOST}/webhook/whatsapp-incoming

# Evolution API JWT secret token for authentication
# Used to sign and verify JWT tokens for API authentication
# Generate with: openssl rand -base64 64
# CRITICAL: This secret protects all API authentication tokens
EVOLUTION_JWT_SECRET=CHANGE_ME_TO_A_SECURE_KEY_MIN_64_CHARS

# Prisma database client identifier (internal - do not change)
# Used by Evolution API's Prisma ORM for connection pool naming
DATABASE_CONNECTION_CLIENT_NAME=evolution_api

# ----------------------------------------------------------------------------
# Lowcoder Configuration
# ----------------------------------------------------------------------------
# Low-code application platform for building custom internal business apps
#
# Lowcoder is a drag-and-drop application builder that connects to databases,
# REST APIs, and other services to create custom admin dashboards, CRUD apps,
# forms, and internal tools without extensive coding.
#
# Key Features:
#   - Visual UI builder with pre-built components (tables, forms, charts)
#   - Data source connections (PostgreSQL, REST APIs, GraphQL, MongoDB)
#   - Application deployment and user management
#   - Integration with n8n workflows via webhooks and API queries
#
# Security Architecture:
#   - MongoDB metadata storage (application definitions, users, datasources)
#   - Redis session management and caching
#   - Encryption keys protect datasource credentials (ENCRYPTION_PASSWORD/SALT)
#   - Admin account required for first-time setup
#   - Network isolation (no port exposure, HTTPS via Caddy only)
#
# Integration Patterns:
#   1. Database Dashboards: Connect to PostgreSQL (n8n_db, chatwoot_db, etc.)
#   2. Workflow Triggers: Webhook calls to n8n workflows from Lowcoder apps
#   3. API Queries: REST API calls to Evolution API, Directus, or other services
#
# ⚠️  CRITICAL SECURITY WARNINGS:
#   1. LOWCODER_ENCRYPTION_PASSWORD/SALT: Protect datasource credentials
#      - Must be 32-character alphanumeric strings
#      - Generate with: openssl rand -base64 32 | tr -d "=+/" | cut -c1-32
#      - NEVER share or commit these keys to version control
#      - Loss of these keys = loss of access to ALL datasource credentials
#      - Store securely (password manager, encrypted backup)
#
#   2. LOWCODER_ADMIN_EMAIL/PASSWORD: First-time admin account
#      - Admin account created automatically on first startup
#      - Change password after first login via Lowcoder web interface
#      - Additional users can be created from admin account
#
#   3. LOWCODER_DB_PASSWORD: MongoDB database access
#      - Already configured above in MongoDB section (line 79)
#      - Used by lowcoder_user to access lowcoder database
#
# Lowcoder hostname (subdomain for Lowcoder service)
# Application builder accessible at: https://${LOWCODER_HOST}
# First login creates admin account using credentials below
LOWCODER_HOST=lowcoder.${DOMAIN}

# Lowcoder admin account (first-time setup)
# Used to create initial admin account on first startup
# ⚠️  IMPORTANT: Change password after first login via Lowcoder UI
# Additional users can be created from admin account
# Example: admin@example.com.br
LOWCODER_ADMIN_EMAIL=admin@${DOMAIN}

# Lowcoder admin password (initial admin account)
# Generate with: openssl rand -base64 32 | tr -d "=+/" | cut -c1-32
# ⚠️  WARNING: Change this password after first login
# Default account has full access to all applications and datasources
LOWCODER_ADMIN_PASSWORD=CHANGE_ME_TO_A_SECURE_PASSWORD_MIN_32_CHARS

# Lowcoder encryption password (protects datasource credentials)
# CRITICAL: Used to encrypt database passwords, API keys in datasource configurations
# Generate with: openssl rand -base64 32 | tr -d "=+/" | cut -c1-32
# Must be exactly 32 characters (alphanumeric)
# ⚠️  BACKUP SECURELY: Without this key, all datasource credentials are inaccessible
LOWCODER_ENCRYPTION_PASSWORD=CHANGE_ME_TO_A_32_CHAR_ALPHANUMERIC_KEY

# Lowcoder encryption salt (additional security for credential encryption)
# Used in combination with ENCRYPTION_PASSWORD for stronger encryption
# Generate with: openssl rand -base64 32 | tr -d "=+/" | cut -c1-32
# Must be exactly 32 characters (alphanumeric)
# ⚠️  BACKUP SECURELY: Required for decrypting datasource credentials
LOWCODER_ENCRYPTION_SALT=CHANGE_ME_TO_A_32_CHAR_ALPHANUMERIC_SALT

# Lowcoder read-only database user password
# This password is used for the lowcoder_readonly_user PostgreSQL account
# This user has SELECT-only permissions on all BorgStack service databases:
#   - n8n_db (workflow data)
#   - chatwoot_db (customer service data)
#   - directus_db (CMS content)
#   - evolution_db (WhatsApp data)
# Generate with: openssl rand -base64 32 | tr -d "=+/" | cut -c1-32
# Used when configuring PostgreSQL datasources in Lowcoder applications
# Security: Read-only access implements principle of least privilege
LOWCODER_READONLY_DB_PASSWORD=CHANGE_ME_TO_A_SECURE_PASSWORD_MIN_32_CHARS

# ----------------------------------------------------------------------------
# Directus Configuration
# ----------------------------------------------------------------------------
# Directus headless CMS and data management platform credentials
#
# Directus provides REST and GraphQL APIs for content delivery, flexible data
# modeling, media asset management, and user/role-based access control.
#
# Key Features:
#   - Content management with custom data models (collections and fields)
#   - REST API and GraphQL API for content delivery
#   - Media asset management (local storage in Story 4.1, S3 migration in Story 5.1)
#   - User and role management for content access control
#   - Real-time updates via WebSocket support
#
# Security Architecture:
#   - DIRECTUS_KEY: Instance identifier (UUID format)
#   - DIRECTUS_SECRET: Auth token signing secret (32+ characters) - protects JWT tokens
#   - Database isolation (directus_user has access only to directus_db)
#   - Network isolation (no port exposure, HTTPS via Caddy only)
#   - Redis caching for API responses and session management
#
# Integration Patterns:
#   - n8n: Workflow automation triggers for content events (create, update, delete)
#   - Lowcoder: Content datasource for custom dashboard applications
#   - REST API: https://directus.${DOMAIN}/items/{collection}
#   - GraphQL API: https://directus.${DOMAIN}/graphql
#
# Storage Strategy:
#   - Story 4.1: Local file storage using borgstack_directus_uploads volume
#   - Story 5.1: Migration to SeaweedFS S3-compatible storage (planned)
#   - Template for S3 migration: config/directus/s3-storage.env.example
#
# ⚠️  CRITICAL SECURITY WARNINGS:
#   1. DIRECTUS_SECRET: Protects authentication tokens (JWT signing)
#      - Must be 32+ characters (generate with: openssl rand -base64 32)
#      - NEVER share or commit this key to version control
#      - Loss of this key = all user sessions invalidated
#      - Required for Directus to start
#
#   2. DIRECTUS_KEY: Instance identifier (UUID format)
#      - Must be unique per Directus deployment
#      - Generate with: uuidgen or openssl rand -hex 16
#      - Used to identify this Directus instance in multi-instance setups
#
#   3. DIRECTUS_DB_PASSWORD: PostgreSQL database access
#      - Already configured above in PostgreSQL section (line 44)
#      - Used by directus_user to access directus_db database
#
#   4. DIRECTUS_ADMIN_EMAIL/PASSWORD: First-time admin account
#      - Admin account created automatically on first startup
#      - Additional users can be created from admin account
#      - Supports fine-grained role and permission management

# Directus hostname (subdomain for Directus service)
# Admin UI accessible at: https://${DIRECTUS_HOST}/admin
# REST API: https://${DIRECTUS_HOST}/items/{collection}
# GraphQL API: https://${DIRECTUS_HOST}/graphql
DIRECTUS_HOST=directus.${DOMAIN}

# Directus instance identifier (UUID format)
# Must be unique per deployment - identifies this Directus instance
# Generate with: uuidgen (Linux/Mac) or openssl rand -hex 16
# Example: 8f7c3b2a-1d4e-4c6b-9a8f-2e5d7c3a6b1f
# ⚠️  IMPORTANT: Must be valid UUID or 32-character hex string
DIRECTUS_KEY=<generate-uuid-with-uuidgen-or-openssl-rand-hex-16>

# Directus authentication token secret (32+ characters)
# Used for JWT token signing - protects all authentication tokens
# Generate with: openssl rand -base64 32
# ⚠️  CRITICAL: BACKUP SECURELY - without this key, all user sessions are invalidated
# ⚠️  WARNING: DIRECTUS_SECRET protects authentication tokens - keep secure
DIRECTUS_SECRET=<generate-secret-with-openssl-rand-base64-32>

# Directus admin account (first-time setup)
# Used to create initial admin account on first startup
# Additional users can be created from admin account with fine-grained roles
# Example: admin@example.com.br
DIRECTUS_ADMIN_EMAIL=admin@${DOMAIN}

# Directus admin password (initial admin account)
# Generate with: openssl rand -base64 24 | tr -d "=+/" | cut -c1-24
# ⚠️  WARNING: Change this password after first login via Directus admin UI
# Default account has full access to all collections and settings
DIRECTUS_ADMIN_PASSWORD=<generate-strong-password-min-24-chars>

# Note: File storage uses local volumes (borgstack_directus_uploads)
# For SeaweedFS integration: Use n8n workflows + Filer HTTP API
# See: docs/04-integrations/seaweedfs-filer-api-n8n.md

# Directus API Token for n8n Integration (Story 4.3)
# ⚠️  MANUAL STEP REQUIRED - This CANNOT be automated:
#   1. Deploy Directus: docker compose up -d directus
#   2. Login to Directus: https://directus.${DOMAIN}/admin
#   3. Go to Settings → Access Tokens
#   4. Click "Create New Token"
#   5. ⚠️  IMPORTANT - Set SCOPED permissions (Principle of Least Privilege):
#      - directus_files: Read, Update (NOT Create/Delete)
#      - This limits the token to only file metadata operations
#   6. Copy generated token and add here
#   7. Used by n8n workflows to query and update Directus file records
# Note: Token grants read/write access to file collection - protect like a password
DIRECTUS_API_TOKEN=<obtain-from-directus-admin-ui-after-first-login>

# Directus Webhook Security (Story 4.3)
# HMAC secret for validating webhook signatures (prevents replay attacks)
# Generate a secure random string (min 32 characters):
#   openssl rand -hex 32
# This same secret must be configured in Directus Flow webhook settings
# Leave empty to disable signature validation (development only)
DIRECTUS_WEBHOOK_SECRET=<generate-secure-random-32-chars>

# ----------------------------------------------------------------------------
# SeaweedFS Configuration
# ----------------------------------------------------------------------------
# S3-compatible object storage configuration

# SeaweedFS admin credentials
# SeaweedFS credentials configured in section below (lines ~680-715)
# Use SEAWEEDFS_ACCESS_KEY and SEAWEEDFS_SECRET_KEY for S3 API access

# ----------------------------------------------------------------------------
# FileFlows Configuration
# ----------------------------------------------------------------------------
# FileFlows automated media processing platform credentials
#
# FileFlows provides automated media file conversion and processing using FFmpeg.
# It watches input directories, applies transformation workflows, and outputs
# processed media files.
#
# Key Features:
#   - FFmpeg-based video/audio/image transcoding
#   - Visual flow designer for processing pipelines
#   - Directory watching for automatic processing
#   - Integration with Directus and n8n for media workflow automation
#
# Architecture:
#   - Node.js application with FFmpeg processing engine
#   - Web UI (port 5000) for flow designer and monitoring
#   - Processing nodes: Local server (configurable concurrency)
#
# Integration Patterns:
#   - Directus → n8n → FileFlows: Trigger processing when media uploaded
#   - FileFlows → n8n: Webhook notification on completion
#   - n8n → Directus: Update CMS with processed media URL
#
# Storage Strategy:
#   - Story 4.2: Local volume storage (borgstack_fileflows_input/output/temp)
#   - Story 5.1: Migration to SeaweedFS S3-compatible storage (planned)
#   - See config/fileflows/s3-storage.env.example for S3 migration template
#
# Security:
#   - Web UI accessible at https://fileflows.${DOMAIN} (via Caddy reverse proxy)
#   - File permissions managed with PUID/PGID
#   - Network isolation (no port exposure, HTTPS via Caddy only)
#
# Processing Capabilities:
#   - Video: H.264/H.265 encoding, resolution scaling, bitrate optimization
#   - Audio: Normalization (loudnorm), format conversion, silence removal
#   - Image: WebP conversion, resizing, compression
#
# ⚠️  IMPORTANT NOTES:
#   1. File storage uses local volumes initially - S3 migration in Story 5.1
#   2. Processing requires adequate disk space (temp directory)
#   3. PUID/PGID must match host user for file access permissions
#   4. Timezone affects log timestamps and scheduled processing

# FileFlows hostname (subdomain for FileFlows service)
# Web UI accessible at: https://${FILEFLOWS_HOST}
# Flow Designer: https://${FILEFLOWS_HOST}/flows
FILEFLOWS_HOST=fileflows.${DOMAIN}

# FileFlows logging level
# Options: Trace, Debug, Information, Warning, Error, Critical
# Recommended: Information (default) for production
# Use Debug or Trace for troubleshooting processing issues
FILEFLOWS_LOG_LEVEL=Information

# Timezone for log timestamps and scheduled processing
# Default: America/Sao_Paulo (São Paulo, Brazil - UTC-3)
# Format: TZ database name (e.g., America/New_York, Europe/London, Asia/Tokyo)
# Used for: Log timestamps, scheduled processing times
TZ=America/Sao_Paulo

# File permission management (User ID and Group ID)
# PUID/PGID must match host user for file access permissions
# Default: 1000 (typical first user on Linux systems)
# Find your UID/GID: id -u && id -g
PUID=1000
PGID=1000

# FileFlows license key (OPTIONAL - for commercial features)
# Free version supports all core processing features
# Commercial license adds: Advanced monitoring, priority support, extended integrations
# Obtain from: https://fileflows.com/pricing
# Leave commented out if using free version
# FILEFLOWS_LICENSE_KEY=<obtain-from-fileflows.com>

# Note: File storage configuration
# Current implementation (Story 4.2) uses local Docker volumes:
#   - Input:  borgstack_fileflows_input  (media files awaiting processing)
#   - Output: borgstack_fileflows_output (processed media files)
#   - Temp:   borgstack_fileflows_temp   (FFmpeg scratch space)
#
# Future implementation (Story 5.1) will migrate to SeaweedFS S3 storage:
#   - See config/fileflows/s3-storage.env.example for S3 configuration template
#   - Migration steps documented in Story 5.1

# ----------------------------------------------------------------------------
# Directus-FileFlows Integration Configuration (Story 4.3)
# ----------------------------------------------------------------------------
# Storage optimization settings for automated media processing

# Delete original files after successful processing
# Options: true | false
# Default: false (keep originals indefinitely)
# Recommended for production: true (save storage space)
# ⚠️  WARNING: Original files cannot be recovered after deletion
# Set to true only if you're confident processed files meet your requirements
FILEFLOWS_DELETE_ORIGINALS=false

# Retention period for original media files before cleanup (days)
# Used by optional cleanup scripts to remove old originals
# Default: 30 (keep originals for 30 days before manual cleanup)
# Set to 0 to disable retention policy (keep indefinitely)
# Note: This does NOT auto-delete files - manual cleanup script required
DIRECTUS_MEDIA_RETENTION_DAYS=30

# ----------------------------------------------------------------------------
# SeaweedFS S3-Compatible Object Storage Configuration
# ----------------------------------------------------------------------------
# S3-compatible distributed object storage for file-heavy services

# S3 API authentication credentials
# ⚠️  IMPORTANT: Generate strong random values using:
#   Access Key:  openssl rand -base64 24  (generates ~32 chars)
#   Secret Key:  openssl rand -base64 48  (generates ~64 chars)
# Store these credentials securely - required for all S3 client access
SEAWEEDFS_ACCESS_KEY=CHANGE_ME_GENERATE_RANDOM_32_CHARS
SEAWEEDFS_SECRET_KEY=CHANGE_ME_GENERATE_RANDOM_64_CHARS

# Volume size limit (MB per volume)
# Default: 10240 (10GB)
# Rationale: Balances file distribution across volumes and parallel write performance
# Each volume can grow up to this size before SeaweedFS creates a new volume
# Recommended: Keep at 10GB for media files unless you have specific requirements
SEAWEEDFS_VOLUME_SIZE_LIMIT_MB=10240

# Replication strategy (XYZ format)
# Format: X = datacenter copies, Y = rack copies, Z = server copies
# Default: 000 (no replication - single server mode)
# Options:
#   000 = No replication (single server) - CURRENT CONFIGURATION
#   001 = 1 copy on different server (requires 2+ servers)
#   011 = 1 rack copy + 1 server copy (requires 2+ racks)
#   100 = 1 datacenter copy (requires 2+ datacenters)
# ⚠️  Change to 001 or higher when adding servers for redundancy
SEAWEEDFS_REPLICATION=000

# Maximum number of volumes (optional)
# Default: 100
# Total storage capacity = SEAWEEDFS_VOLUME_SIZE_LIMIT_MB × SEAWEEDFS_MAX_VOLUMES
# Example: 10240 MB × 100 = 1024000 MB (1 TB total capacity)
# Increase if you need more storage capacity
SEAWEEDFS_MAX_VOLUMES=100

# Volume pre-allocation (optional)
# Default: false
# Set to true to pre-allocate volume files for consistent performance
# Rationale: Reduces fragmentation and improves write performance
# Caveat: Allocates disk space upfront (VOLUME_SIZE_LIMIT_MB per volume)
SEAWEEDFS_VOLUME_PREALLOCATE=false

# S3 endpoint information (for reference)
# ℹ️  Internal endpoint (services): http://seaweedfs:8333
# ℹ️  External endpoint (optional): https://s3.${BORGSTACK_DOMAIN} (requires Caddy configuration)
# ℹ️  Use internal endpoint for service-to-service communication (Directus, FileFlows, n8n)
# ℹ️  Configure external endpoint only if you need S3 access from outside Docker network

# Bucket organization (for reference - buckets created in Story 5.1)
# Main bucket: borgstack
# Subdirectories:
#   /borgstack/n8n/              - n8n workflow attachments
#   /borgstack/chatwoot/         - Chatwoot conversation files and avatars
#   /borgstack/directus/         - Directus CMS assets (migrated in Story 5.3)
#   /borgstack/fileflows/        - FileFlows processed media (migrated in Story 5.3)
#   /borgstack/lowcoder/         - Lowcoder app assets
#   /borgstack/duplicati/        - Backup staging area

# ============================================================================
# Duplicati Backup System
# ============================================================================
# Duplicati provides automated, encrypted backups of all BorgStack data.
#
# Version: Duplicati 2.1.1.102
#
# Features:
# - Incremental backups (only changed data backed up after initial full backup)
# - AES-256 encryption before upload to external storage
# - Multiple backup destinations (S3, Backblaze B2, FTP, WebDAV, local drives)
# - Retention policy: 7 daily + 4 weekly + 12 monthly backups (configurable)
# - Automatic deduplication (reduces storage costs)
# - Web UI for configuration: https://duplicati.${BORGSTACK_DOMAIN}
#
# CRITICAL SECURITY NOTES:
# 1. Store DUPLICATI_PASSPHRASE in a secure password manager
# 2. WITHOUT the passphrase, backups CANNOT be restored!
# 3. Backup the passphrase SEPARATELY from the backup destination
# 4. Do NOT lose the passphrase - there is no recovery mechanism
#
# Brazilian Data Sovereignty Recommendations:
# - Backblaze B2 (cost-effective, privacy-focused)
# - AWS S3 São Paulo region (sa-east-1)
# - Local/network drives for air-gapped backups

# Duplicati web UI password
# Used to access the backup configuration interface at https://duplicati.${BORGSTACK_DOMAIN}
# Generate: openssl rand -base64 32
DUPLICATI_PASSWORD=CHANGE_ME_TO_A_SECURE_PASSWORD_MIN_32_CHARS

# Duplicati server encryption key
# Encrypts backup job configurations stored in Duplicati's SQLite database
# Generate: openssl rand -base64 64
DUPLICATI_ENCRYPTION_KEY=CHANGE_ME_TO_A_SECURE_KEY_MIN_64_CHARS

# Duplicati backup passphrase (CRITICAL - STORE SECURELY!)
# This passphrase encrypts ALL backup data before upload using AES-256
# WITHOUT this passphrase, you CANNOT restore your backups!
#
# IMPORTANT INSTRUCTIONS:
# 1. Generate a strong passphrase (minimum 32 characters, recommend 64+)
# 2. Store this passphrase in a secure password manager (NOT in this file alone)
# 3. Write it down and store physically in a safe location
# 4. Share with trusted team members via secure channels
# 5. NEVER lose this passphrase - it cannot be recovered!
#
# Generate: openssl rand -base64 48
DUPLICATI_PASSPHRASE=CHANGE_ME_TO_A_SECURE_PASSPHRASE_AND_STORE_IN_PASSWORD_MANAGER

# ============================================================================
# Backup Configuration
# ============================================================================
# Configure external backup destinations (optional)

# Example: S3-compatible storage
# BACKUP_S3_ENDPOINT=https://s3.amazonaws.com
# BACKUP_S3_BUCKET=borgstack-backups
# BACKUP_S3_ACCESS_KEY=YOUR_ACCESS_KEY
# BACKUP_S3_SECRET_KEY=YOUR_SECRET_KEY

# Example: FTP/SFTP
# BACKUP_FTP_HOST=ftp.example.com
# BACKUP_FTP_USERNAME=backup_user
# BACKUP_FTP_PASSWORD=CHANGE_ME

# ============================================================================
# Email Configuration (Optional)
# ============================================================================
# Configure SMTP for email notifications from services

# SMTP server configuration
# SMTP_HOST=smtp.example.com
# SMTP_PORT=587
# SMTP_USERNAME=notifications@example.com
# SMTP_PASSWORD=CHANGE_ME
# SMTP_FROM_EMAIL=noreply@example.com
# SMTP_FROM_NAME=BorgStack

# ============================================================================
# Advanced Configuration
# ============================================================================

# Timezone (default: UTC)
TZ=UTC

# Log level (debug, info, warn, error)
LOG_LEVEL=info

# ============================================================================
# End of Configuration
# ============================================================================
