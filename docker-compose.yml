# BorgStack - Docker Compose Configuration
# Docker Compose v2 Format
#
# This is the main orchestration file for BorgStack.
# Services will be added incrementally as the project develops.
#
# Architecture: All services share borgstack_internal network for inter-service communication
# External access is routed through Caddy reverse proxy on borgstack_external network
#
# IMPORTANT: Always pin exact image versions. Never use 'latest' tag.

# Services will be defined here as we build out the stack
services:
  # ==========================================================================
  # PostgreSQL Database (Shared)
  # ==========================================================================
  # Primary relational database for n8n, Chatwoot, Directus, and Evolution API
  # Image: pgvector/pgvector:pg18 (PostgreSQL 18.0 with pgvector extension)
  # pgvector extension enables vector similarity search for AI/LLM features
  #
  # Database Organization:
  #   - n8n_db: n8n workflow automation (pgvector enabled for AI nodes)
  #   - chatwoot_db: Chatwoot customer service platform
  #   - directus_db: Directus headless CMS (pgvector enabled for AI features)
  #   - evolution_db: Evolution API WhatsApp gateway
  #
  # Connection Strings (for use in future service stories):
  #   n8n:         postgres://n8n_user:${N8N_DB_PASSWORD}@postgresql:5432/n8n_db
  #   Chatwoot:    postgres://chatwoot_user:${CHATWOOT_DB_PASSWORD}@postgresql:5432/chatwoot_db
  #   Directus:    postgres://directus_user:${DIRECTUS_DB_PASSWORD}@postgresql:5432/directus_db
  #   Evolution:   postgres://evolution_user:${EVOLUTION_DB_PASSWORD}@postgresql:5432/evolution_db
  #
  # Security:
  #   - NO port exposure to host (internal network access only per Story 1.2)
  #   - Each service has dedicated database and user (principle of least privilege)
  #   - Services connect using Docker DNS: postgresql:5432
  #
  # Performance:
  #   - Tuned for 36GB RAM server
  #   - shared_buffers=8GB, effective_cache_size=24GB
  #   - max_connections=200 for connection pooling
  #   - SSD-optimized settings (random_page_cost=1.1)
  #
  # Backup Strategy:
  #   - Automated: Duplicati (Story 5.2) backs up borgstack_postgresql_data volume
  #   - Manual backup: docker compose exec postgresql pg_dumpall -U postgres > backup.sql
  #   - Manual restore: docker compose exec -T postgresql psql -U postgres < backup.sql
  # ==========================================================================
  postgresql:
    image: pgvector/pgvector:pg18
    container_name: borgstack_postgresql
    restart: unless-stopped
    networks:
      - borgstack_internal
    # ⚠️  NO ports section in production - databases must not expose ports to host
    # ℹ️  For local development, add port mapping in docker-compose.override.yml
    volumes:
      - borgstack_postgresql_data:/var/lib/postgresql/data
      - ./config/postgresql/init-databases.sh:/docker-entrypoint-initdb.d/01-init-databases.sh:ro
      - ./config/postgresql/postgresql.conf:/etc/postgresql/postgresql.conf:ro
      - ./config/postgresql/pg_hba.conf:/etc/postgresql/pg_hba.conf:ro
    environment:
      # PostgreSQL superuser password (for administration only)
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      # Service-specific database passwords (used in init-databases.sh)
      N8N_DB_PASSWORD: ${N8N_DB_PASSWORD}
      CHATWOOT_DB_PASSWORD: ${CHATWOOT_DB_PASSWORD}
      DIRECTUS_DB_PASSWORD: ${DIRECTUS_DB_PASSWORD}
      EVOLUTION_DB_PASSWORD: ${EVOLUTION_DB_PASSWORD}
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s
      # Increased from 30s to 60s for CI environment compatibility
      # Test script uses 180s timeout - this provides adequate startup buffer
    # Load custom postgresql.conf with performance tuning
    command: >
      postgres
      -c config_file=/etc/postgresql/postgresql.conf
      -c hba_file=/etc/postgresql/pg_hba.conf

  # ==========================================================================
  # Redis Cache & Queue
  # ==========================================================================
  # Shared cache and message queue for all application services
  # Image: redis:8.2-alpine (Alpine Linux base for minimal footprint)
  #
  # Service Usage:
  #   - n8n:      Session management, Bull queue processing (DB 0)
  #   - Chatwoot: Session management, Sidekiq background jobs (DB 0)
  #   - Lowcoder: Session storage (DB 0)
  #   - Directus: Caching layer (DB 0)
  #
  # Connection Strings (for use in future service stories):
  #   Standard format: redis://:${REDIS_PASSWORD}@redis:6379
  #   n8n:             QUEUE_BULL_REDIS_HOST=redis QUEUE_BULL_REDIS_PORT=6379 QUEUE_BULL_REDIS_PASSWORD=${REDIS_PASSWORD}
  #   Chatwoot:        REDIS_HOST=redis REDIS_PORT=6379 REDIS_PASSWORD=${REDIS_PASSWORD}
  #   Lowcoder:        LOWCODER_REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379
  #   Directus:        REDIS_HOST=redis REDIS_PORT=6379 REDIS_PASSWORD=${REDIS_PASSWORD}
  #
  # Security:
  #   - NO port exposure to host (internal network access only per Story 1.2)
  #   - Password authentication required (--requirepass flag)
  #   - Dangerous commands disabled (FLUSHALL, FLUSHDB, CONFIG)
  #   - Services connect using Docker DNS: redis:6379
  #
  # Performance:
  #   - Tuned for 36GB RAM server (8GB allocation)
  #   - Memory eviction policy: allkeys-lru (optimal for cache workload)
  #   - Persistence: RDB snapshots + AOF for durability
  #   - Target: >10,000 ops/sec throughput
  #
  # Monitoring Commands:
  #   Memory usage:    docker compose exec redis redis-cli -a ${REDIS_PASSWORD} INFO memory | grep used_memory_human
  #   Cache hit rate:  docker compose exec redis redis-cli -a ${REDIS_PASSWORD} INFO stats | grep -E "keyspace_hits|keyspace_misses"
  #   Connected clients: docker compose exec redis redis-cli -a ${REDIS_PASSWORD} INFO clients | grep connected_clients
  #   Operations/sec:  docker compose exec redis redis-cli -a ${REDIS_PASSWORD} INFO stats | grep instantaneous_ops_per_sec
  #   Benchmark:       docker compose exec redis redis-benchmark -h localhost -p 6379 -a ${REDIS_PASSWORD} -t get,set -n 100000 -q
  # ==========================================================================
  redis:
    image: redis:8.2-alpine
    container_name: borgstack_redis
    restart: unless-stopped
    networks:
      - borgstack_internal
    # ⚠️  NO ports section in production - cache must not expose ports to host
    # ℹ️  For local development, add port mapping in docker-compose.override.yml
    volumes:
      - borgstack_redis_data:/data
      - ./config/redis/redis.conf:/usr/local/etc/redis/redis.conf:ro
    environment:
      # Redis password (used in health check and passed via command line)
      REDIS_PASSWORD: ${REDIS_PASSWORD}
    # Start Redis with custom config and password authentication
    # --requirepass allows environment variable substitution
    command: redis-server /usr/local/etc/redis/redis.conf --requirepass ${REDIS_PASSWORD}
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    # Memory limit matches maxmemory setting in redis.conf
    deploy:
      resources:
        limits:
          memory: 8192M

  # ==========================================================================
  # Caddy Reverse Proxy
  # ==========================================================================
  # HTTPS termination and routing gateway for all web services
  # Image: caddy:2.10-alpine (Alpine Linux base for minimal footprint)
  #
  # Architecture:
  #   - Single entry point for all HTTPS traffic (ONLY service exposing ports to host)
  #   - Automatic SSL certificate provisioning and renewal via Let's Encrypt
  #   - Routes to internal services on borgstack_external network using Docker DNS
  #   - HTTP to HTTPS redirection automatic (built-in Caddy feature)
  #
  # Service Access Patterns (configured in config/caddy/Caddyfile):
  #   https://n8n.{DOMAIN}      → http://n8n:5678       (Story 2.1)
  #   https://chatwoot.{DOMAIN} → http://chatwoot:3000  (Story 3.1)
  #   https://evolution.{DOMAIN}→ http://evolution:8080 (Story 2.2)
  #   https://lowcoder.{DOMAIN} → http://lowcoder:3000  (Story 3.2)
  #   https://directus.{DOMAIN} → http://directus:8055  (Story 4.1)
  #   https://fileflows.{DOMAIN}→ http://fileflows:5000 (Story 4.2)
  #   https://duplicati.{DOMAIN}→ http://duplicati:8200 (Story 5.2)
  #
  # SSL/TLS Certificates:
  #   - Automatic HTTPS enabled for all configured domains
  #   - Let's Encrypt certificates auto-provisioned on first request
  #   - Auto-renewal 30 days before expiration
  #   - Certificates stored in borgstack_caddy_data volume
  #   - Requires: DNS A records pointing to server IP, ports 80/443 accessible
  #
  # Security:
  #   - ONLY service exposing ports 80/443 to host (per Story 1.2 network architecture)
  #   - All other services access external traffic through Caddy routing
  #   - Security headers configured in Caddyfile (X-Frame-Options, CSP, CORS)
  #   - Admin API on port 2019 (internal only, not exposed to host)
  #
  # Configuration Management:
  #   - Caddyfile stored in version control (./config/caddy/Caddyfile)
  #   - Auto-saved JSON config in borgstack_caddy_config volume
  #   - Reload config: docker compose exec caddy caddy reload --config /etc/caddy/Caddyfile
  #
  # Health Monitoring:
  #   Health check:    docker compose ps caddy
  #   Admin API:       docker compose exec caddy wget -qO- http://localhost:2019/config/
  #   Certificate info: docker compose exec caddy ls -lah /data/caddy/certificates/
  # ==========================================================================
  caddy:
    image: caddy:2.10-alpine
    container_name: borgstack_caddy
    restart: unless-stopped
    networks:
      - borgstack_external
    # ✅ ONLY service that exposes ports to host (single entry point architecture)
    ports:
      - "80:80"    # HTTP (automatically redirects to HTTPS)
      - "443:443"  # HTTPS (SSL/TLS termination)
    volumes:
      # Caddyfile configuration (read-only for security)
      - ./config/caddy/Caddyfile:/etc/caddy/Caddyfile:ro
      # Certificate storage (Let's Encrypt certificates and account data)
      - borgstack_caddy_data:/data
      # Auto-saved JSON config (Caddy's internal representation)
      - borgstack_caddy_config:/config
    environment:
      # Base domain for all services (e.g., example.com.br)
      # Subdomains will be: n8n.{DOMAIN}, chatwoot.{DOMAIN}, etc.
      DOMAIN: ${DOMAIN:-localhost}
      # Email for Let's Encrypt account notifications
      EMAIL: ${EMAIL:-admin@localhost}
      # CORS allowed origins for API services (Evolution API, Directus)
      # Production: Set to specific origins (e.g., https://app.example.com.br)
      # Development: Use "*" for testing (default)
      CORS_ALLOWED_ORIGINS: ${CORS_ALLOWED_ORIGINS:-*}
    healthcheck:
      # Verify Caddy process is running
      test: ["CMD", "caddy", "version"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 5s

  # ==========================================================================
  # n8n Workflow Automation Platform
  # ==========================================================================
  # Central workflow orchestration hub connecting all services
  # Image: n8nio/n8n:1.112.6
  #
  # Architecture:
  #   - Connects to PostgreSQL (n8n_db) for workflow storage
  #   - Connects to Redis for Bull queue and session management
  #   - Exposed via Caddy reverse proxy (n8n.{DOMAIN})
  #   - Webhook endpoints: https://${N8N_HOST}/webhook/{path}
  #
  # Security:
  #   - Basic authentication enabled (N8N_BASIC_AUTH_ACTIVE=true)
  #   - Encryption key protects workflow credentials (N8N_ENCRYPTION_KEY)
  #   - Database user isolation (n8n_user with access only to n8n_db)
  #   - Network isolation (internal for DB/Redis, external for Caddy)
  #
  # Integration Patterns:
  #   - HTTP Request nodes for service-to-service communication
  #   - Webhook triggers for external event reception
  #   - Database storage for workflow definitions and executions
  #   - Redis queue for background job processing
  # ==========================================================================
  n8n:
    image: n8nio/n8n:1.112.6
    container_name: borgstack_n8n
    restart: unless-stopped
    networks:
      - borgstack_internal
      - borgstack_external
    environment:
      # Database connection (PostgreSQL)
      DB_TYPE: postgresdb
      DB_POSTGRESDB_HOST: postgresql
      DB_POSTGRESDB_PORT: 5432
      DB_POSTGRESDB_DATABASE: n8n_db
      DB_POSTGRESDB_USER: n8n_user
      DB_POSTGRESDB_PASSWORD: ${N8N_DB_PASSWORD}

      # Redis connection (Bull queue)
      QUEUE_BULL_REDIS_HOST: redis
      QUEUE_BULL_REDIS_PORT: 6379
      QUEUE_BULL_REDIS_PASSWORD: ${REDIS_PASSWORD}
      QUEUE_BULL_REDIS_DB: 0

      # n8n configuration
      N8N_HOST: n8n.${DOMAIN}
      N8N_PROTOCOL: https
      N8N_PORT: 5678
      WEBHOOK_URL: https://n8n.${DOMAIN}/

      # Encryption key for credential storage
      N8N_ENCRYPTION_KEY: ${N8N_ENCRYPTION_KEY}

      # Basic authentication
      N8N_BASIC_AUTH_ACTIVE: true
      N8N_BASIC_AUTH_USER: ${N8N_BASIC_AUTH_USER}
      N8N_BASIC_AUTH_PASSWORD: ${N8N_BASIC_AUTH_PASSWORD}

      # Timezone
      GENERIC_TIMEZONE: America/Sao_Paulo

      # Health check and metrics
      N8N_METRICS: "true"
      QUEUE_HEALTH_CHECK_ACTIVE: "true"
    volumes:
      - borgstack_n8n_data:/home/node/.n8n
      # Volume mounts for Directus-FileFlows integration (Story 4.3)
      # Read-only access to Directus uploads for copying files to FileFlows
      - borgstack_directus_uploads:/directus/uploads:ro
      # Read-write access to FileFlows input for file processing trigger
      - borgstack_fileflows_input:/fileflows/input:rw
    depends_on:
      postgresql:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "wget --quiet --tries=1 --spider http://127.0.0.1:5678/healthz/readiness || exit 1"]
      interval: 60s
      timeout: 10s
      retries: 10
      start_period: 180s
      # Increased from 90s to 180s for CI environment compatibility
      # Test script uses 600s timeout with migration detection
      # Database migrations + Redis connection may take 3-5 minutes in CI

  # ==========================================================================
  # Evolution API - WhatsApp Business Gateway
  # ==========================================================================
  # Multi-instance WhatsApp Business API gateway for sending/receiving messages
  # Image: atendai/evolution-api:v2.2.3
  #
  # Architecture:
  #   - Connects to PostgreSQL (evolution_db) for message storage and instance management
  #   - Connects to Redis for session management and caching
  #   - Exposed via Caddy reverse proxy (evolution.{DOMAIN})
  #   - Webhook delivery to n8n for incoming WhatsApp messages
  #
  # Multi-Instance Support:
  #   - Each WhatsApp business account gets its own instance (isolated sessions)
  #   - Instance creation via API: POST /instance/create with instance name
  #   - QR code authentication: Scan QR code in WhatsApp to connect
  #   - Sessions stored in borgstack_evolution_instances volume
  #
  # Security:
  #   - API key authentication (AUTHENTICATION_API_KEY)
  #   - Instance-level authentication enabled
  #   - Database user isolation (evolution_user with access only to evolution_db)
  #   - Network isolation (internal for DB/Redis, external for Caddy)
  #   - No port exposure to host (HTTPS access via Caddy only)
  #
  # Integration Patterns:
  #   - Webhook to n8n: Incoming messages sent to https://{N8N_HOST}/webhook/whatsapp-incoming
  #   - HTTP API: n8n sends messages via POST /message/sendText/{instanceName}
  #   - Admin UI: https://evolution.{DOMAIN}/manager
  #   - API Documentation: https://evolution.{DOMAIN}/docs
  #
  # API Endpoints:
  #   - Root/Health Check: GET / (returns 200 OK when healthy)
  #   - Instance Creation: POST /instance/create (requires apikey header)
  #   - Send Message: POST /message/sendText/{instanceName} (requires apikey header)
  #   - Admin UI: GET /manager (web interface for instance management)
  # ==========================================================================
  evolution:
    image: atendai/evolution-api:v2.2.3
    container_name: borgstack_evolution
    restart: unless-stopped
    networks:
      - borgstack_internal
      - borgstack_external
    environment:
      # Database connection
      DATABASE_ENABLED: true
      DATABASE_PROVIDER: postgresql
      DATABASE_URL: postgresql://evolution_user:${EVOLUTION_DB_PASSWORD}@postgresql:5432/evolution_db
      DATABASE_CONNECTION_URI: postgresql://evolution_user:${EVOLUTION_DB_PASSWORD}@postgresql:5432/evolution_db
      DATABASE_CONNECTION_CLIENT_NAME: evolution_api
      DATABASE_SAVE_DATA_INSTANCE: true
      DATABASE_SAVE_DATA_NEW_MESSAGE: true
      DATABASE_SAVE_MESSAGE_UPDATE: true
      DATABASE_SAVE_DATA_CONTACTS: true
      DATABASE_SAVE_DATA_CHATS: true

      # Redis cache connection
      CACHE_REDIS_ENABLED: true
      CACHE_REDIS_URI: redis://:${REDIS_PASSWORD}@redis:6379
      CACHE_REDIS_PREFIX_KEY: evolution
      CACHE_REDIS_SAVE_INSTANCES: false
      CACHE_LOCAL_ENABLED: false

      # Evolution API configuration
      SERVER_URL: https://${EVOLUTION_HOST}
      SERVER_PORT: 8080

      # Authentication
      AUTHENTICATION_API_KEY: ${EVOLUTION_API_KEY}
      AUTHENTICATION_INSTANCE_ENABLED: true

      # Webhook configuration
      WEBHOOK_GLOBAL_ENABLED: true
      WEBHOOK_GLOBAL_URL: ${EVOLUTION_WEBHOOK_URL}
      WEBHOOK_GLOBAL_WEBHOOK_BY_EVENTS: true

      # WhatsApp session configuration
      CONFIG_SESSION_PHONE_CLIENT: BorgStack WhatsApp Gateway
      CONFIG_SESSION_PHONE_NAME: BorgStack

      # QR code customization
      QRCODE_COLOR: '#198754'
      QRCODE_LIMIT: 30

      # Log level
      LOG_LEVEL: ERROR
      LOG_COLOR: true

    volumes:
      - borgstack_evolution_instances:/evolution/instances
    depends_on:
      postgresql:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "wget --quiet --tries=1 --spider http://127.0.0.1:8080/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
      # Increased from 60s to 120s for CI environment compatibility
      # Prisma migrations + Redis connection may take longer in CI

  # ==========================================================================
  # Chatwoot - Customer Service Platform
  # ==========================================================================
  # Omnichannel customer communication platform with agent management
  # Image: chatwoot/chatwoot:v4.6.0-ce
  #
  # Architecture:
  #   - Connects to PostgreSQL (chatwoot_db) for data storage
  #   - Connects to Redis for Sidekiq background jobs and session management
  #   - Exposed via Caddy reverse proxy (chatwoot.{DOMAIN})
  #   - Webhook integration with Evolution API via n8n for WhatsApp support
  #
  # Security:
  #   - SECRET_KEY_BASE (128-char hex) protects Rails sessions
  #   - Database user isolation (chatwoot_user with access only to chatwoot_db)
  #   - Network isolation (internal for DB/Redis, external for Caddy)
  #   - No port exposure to host (HTTPS access via Caddy only)
  #
  # Integration Patterns:
  #   - WhatsApp: Evolution API → n8n → Chatwoot API (incoming messages)
  #   - WhatsApp: Chatwoot webhook → n8n → Evolution API (outgoing replies)
  #   - Admin UI: https://chatwoot.{DOMAIN}/app
  #   - API Base URL: https://chatwoot.{DOMAIN}/api/v1
  #
  # API Authentication:
  #   - API access token required (CHATWOOT_API_TOKEN)
  #   - Token generated from Chatwoot admin UI after first login
  #   - Token stored in .env for n8n integration workflows
  #
  # Storage Strategy:
  #   - Local volumes for MVP (borgstack_chatwoot_storage, borgstack_chatwoot_public)
  #   - SeaweedFS integration deferred to Epic 5 (Story 5.3)
  # ==========================================================================
  chatwoot:
    image: chatwoot/chatwoot:v4.6.0-ce
    container_name: borgstack_chatwoot
    restart: unless-stopped
    networks:
      - borgstack_internal
      - borgstack_external
    entrypoint: docker/entrypoints/rails.sh
    command: ['sh', '-c', 'bundle exec rails db:chatwoot_prepare && bundle exec rails s -p 3000 -b 0.0.0.0']
    environment:
      # PostgreSQL connection (single source of truth)
      DATABASE_URL: postgresql://chatwoot_user:${CHATWOOT_DB_PASSWORD}@postgresql:5432/chatwoot_db

      # Redis connection
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379

      # Rails configuration
      SECRET_KEY_BASE: ${CHATWOOT_SECRET_KEY_BASE}
      RAILS_ENV: production
      RAILS_LOG_TO_STDOUT: "true"

      # Chatwoot configuration
      FRONTEND_URL: https://${CHATWOOT_HOST}
      INSTALLATION_NAME: BorgStack Chatwoot
    volumes:
      - borgstack_chatwoot_storage:/app/storage
      - borgstack_chatwoot_public:/app/public
    depends_on:
      postgresql:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      # Verify Chatwoot API endpoint is responding (equivalent to curl -I localhost:3000/api)
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://127.0.0.1:3000/api || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 180s
      # Increased from 90s to 180s for CI environment compatibility
      # Rationale for 180s start_period:
      #   - Rails database migrations: ~30-45s (ActiveRecord schema creation)
      #   - Webpacker asset compilation: ~20-30s (JavaScript/CSS bundles)
      #   - Sidekiq worker initialization: ~10s (background job processor)
      #   - Puma web server startup: ~5s (Rails application server)
      #   - CI environment overhead: +60-90s additional buffer for slower CI systems
      # Total: ~65-90s local, ~125-180s in CI (180s provides safety margin)

  # ==========================================================================
  # MongoDB Database (Dedicated for Lowcoder)
  # ==========================================================================
  # NoSQL database exclusively for Lowcoder metadata and configuration storage
  # Image: mongo:7.0
  #
  # Database Organization:
  #   - lowcoder: Lowcoder low-code platform database
  #   - Root admin: admin user (administrative tasks only)
  #   - Service user: lowcoder_user (application access with scoped permissions)
  #
  # Connection String (for use in Story 3.2 - Lowcoder service deployment):
  #   LOWCODER_MONGODB_URL=mongodb://lowcoder_user:${LOWCODER_DB_PASSWORD}@mongodb:27017/lowcoder?authSource=lowcoder
  #
  # Database Isolation Strategy:
  #   - MongoDB dedicated exclusively to Lowcoder (no other services)
  #   - Separation from PostgreSQL maintains clear service boundaries
  #   - Lowcoder requires NoSQL for flexible application metadata storage
  #   - Independent scaling and tuning for Lowcoder workload
  #
  # Security:
  #   - NO port exposure to host (internal network access only)
  #   - Authentication required (root admin + service-specific user)
  #   - lowcoder_user has readWrite + dbAdmin roles on lowcoder database only
  #   - Principle of least privilege enforced via RBAC
  #
  # Backup Strategy:
  #   - Automated: Duplicati (Story 5.2) backs up borgstack_mongodb_data volume
  #   - Manual backup: docker compose exec -T mongodb mongodump --username admin --password ${MONGODB_ROOT_PASSWORD} --authenticationDatabase admin --out /backup/$(date +%Y%m%d_%H%M%S)
  #   - Manual restore: docker compose exec -T mongodb mongorestore --username admin --password ${MONGODB_ROOT_PASSWORD} --authenticationDatabase admin /backup/BACKUP_FOLDER_NAME
  # ==========================================================================
  mongodb:
    image: mongo:7.0
    container_name: borgstack_mongodb
    restart: unless-stopped
    networks:
      - borgstack_internal
    # ⚠️  NO ports section in production - databases must not expose ports to host
    # ℹ️  For local development, add port mapping in docker-compose.override.yml
    environment:
      # MongoDB root admin credentials (for administrative tasks only)
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: ${MONGODB_ROOT_PASSWORD}
      # Lowcoder database user password (used in init-mongo.js initialization script)
      LOWCODER_DB_PASSWORD: ${LOWCODER_DB_PASSWORD}
    volumes:
      # MongoDB data directory (persistent storage for all databases)
      - borgstack_mongodb_data:/data/db
      # Initialization script (creates lowcoder database and user on first startup)
      - ./config/mongodb/init-mongo.js:/docker-entrypoint-initdb.d/init-mongo.js:ro
    healthcheck:
      # Verify MongoDB is responding to commands
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # ==========================================================================
  # Lowcoder Application Platform
  # ==========================================================================
  # Low-code platform for building custom internal business applications
  # Image: lowcoderorg/lowcoder-ce:2.7.4 (Lowcoder Community Edition)
  #
  # Purpose:
  #   - Build custom applications with drag-and-drop UI builder
  #   - Connect to PostgreSQL, REST APIs, and other data sources
  #   - Create admin dashboards, CRUD apps, forms, and custom workflows
  #   - Integration hub for n8n workflows and other BorgStack services
  #
  # Architecture:
  #   - Dual service: Java Spring Boot (API) + Node.js (Node service)
  #   - Port 3000: Web UI and API endpoint
  #   - Port 6060: Node.js service (internal)
  #
  # Database Dependencies:
  #   - MongoDB: Application metadata (apps, queries, users, datasources)
  #   - Redis: Session management and caching
  #
  # Integration Patterns:
  #   - Webhook triggers to n8n workflows
  #   - API queries to n8n endpoints
  #   - PostgreSQL datasource connections (n8n_db, chatwoot_db, etc.)
  #   - Custom app deployment and user management
  #
  # Access:
  #   - Web UI: https://lowcoder.{DOMAIN} (via Caddy reverse proxy)
  #   - First-time login creates admin account using LOWCODER_ADMIN_EMAIL/PASSWORD
  #
  # Security:
  #   - NO port exposure to host (access via Caddy only)
  #   - Encryption keys for datasource credentials (LOWCODER_ENCRYPTION_PASSWORD/SALT)
  #   - Dedicated MongoDB database (lowcoder) with isolated user (lowcoder_user)
  #   - HTTPS enforced via Caddy with automatic Let's Encrypt SSL
  #
  # Backup Strategy:
  #   - MongoDB lowcoder database: Via Duplicati automated backups
  #   - Application stacks volume: borgstack_lowcoder_stacks backed up by Duplicati
  # ==========================================================================
  # ==========================================================================
  # Lowcoder API Service
  # ==========================================================================
  # Spring Boot backend service for Lowcoder platform
  lowcoder-api-service:
    image: lowcoderorg/lowcoder-ce-api-service:2.7.4
    container_name: borgstack_lowcoder_api_service
    restart: unless-stopped
    networks:
      - borgstack_internal
    volumes:
      - borgstack_lowcoder_stacks:/lowcoder-stacks
    environment:
      - LOWCODER_PUID=9001
      - LOWCODER_PGID=9001
      - LOWCODER_MONGODB_URL=mongodb://lowcoder_user:${LOWCODER_DB_PASSWORD}@mongodb:27017/lowcoder?authSource=lowcoder
      - LOWCODER_REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379
      - LOWCODER_DB_ENCRYPTION_PASSWORD=${LOWCODER_ENCRYPTION_PASSWORD}
      - LOWCODER_DB_ENCRYPTION_SALT=${LOWCODER_ENCRYPTION_SALT}
      - LOWCODER_CORS_DOMAINS=*
      - LOWCODER_MAX_QUERY_TIMEOUT=120
      - LOWCODER_MAX_REQUEST_SIZE=20m
    depends_on:
      mongodb:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:8080/api/status/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 180s

  # ==========================================================================
  # Lowcoder Node Service
  # ==========================================================================
  # Node.js service for JavaScript execution
  lowcoder-node-service:
    image: lowcoderorg/lowcoder-ce-node-service:2.7.4
    container_name: borgstack_lowcoder_node_service
    restart: unless-stopped
    networks:
      - borgstack_internal
    environment:
      - LOWCODER_PUID=9001
      - LOWCODER_PGID=9001
      - LOWCODER_API_SERVICE_URL=http://lowcoder-api-service:8080
    depends_on:
      lowcoder-api-service:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:6060"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # ==========================================================================
  # Lowcoder Frontend
  # ==========================================================================
  # Web frontend for Lowcoder platform
  lowcoder-frontend:
    image: lowcoderorg/lowcoder-ce-frontend:2.7.4
    container_name: borgstack_lowcoder_frontend
    restart: unless-stopped
    networks:
      - borgstack_internal
      - borgstack_external
    environment:
      - LOWCODER_PUID=9001
      - LOWCODER_PGID=9001
      - LOWCODER_MAX_QUERY_TIMEOUT=120
      - LOWCODER_MAX_REQUEST_SIZE=20m
      - LOWCODER_API_SERVICE_URL=http://lowcoder-api-service:8080
      - LOWCODER_NODE_SERVICE_URL=http://lowcoder-node-service:6060
    depends_on:
      lowcoder-api-service:
        condition: service_healthy
      lowcoder-node-service:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:3000"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # ==========================================================================
  # Directus - Headless CMS and Data Management
  # ==========================================================================
  # Headless CMS providing REST and GraphQL APIs for content delivery
  # Image: directus/directus:11
  #
  # Purpose:
  #   - Content management with flexible data modeling
  #   - REST API and GraphQL API for content delivery
  #   - Media asset management with local storage (S3 migration in Story 5.1)
  #   - User and role management for content access control
  #
  # Architecture:
  #   - Backend: Node.js + Express + Knex.js (database abstraction)
  #   - Database Migrations: Knex.js migrations (automatic on startup)
  #   - File Storage: Local volume (borgstack_directus_uploads) - migrating to SeaweedFS S3 in Story 5.1
  #   - Port 8055: Web UI (Admin Panel) + REST API + GraphQL API
  #
  # Database Dependencies:
  #   - PostgreSQL: Content storage (directus_db)
  #   - Redis: Caching layer for API responses and session management
  #
  # Integration Patterns:
  #   - n8n: Workflow automation triggers for content events
  #   - Lowcoder: Content datasource for custom applications
  #   - REST API: https://directus.{DOMAIN}/items/{collection}
  #   - GraphQL API: https://directus.{DOMAIN}/graphql
  #
  # Access:
  #   - Web UI: https://directus.{DOMAIN}/admin (via Caddy reverse proxy)
  #   - First-time login creates admin account using DIRECTUS_ADMIN_EMAIL/PASSWORD
  #
  # Security:
  #   - NO port exposure to host (access via Caddy only)
  #   - DIRECTUS_KEY: Instance identifier (UUID format)
  #   - DIRECTUS_SECRET: Auth token signing secret (32+ characters)
  #   - Database user isolation (directus_user with access only to directus_db)
  #   - HTTPS enforced via Caddy with automatic Let's Encrypt SSL
  #
  # Storage Strategy:
  #   - Story 4.1: Local file storage using borgstack_directus_uploads volume
  #   - Story 5.1: Migration to SeaweedFS S3-compatible storage
  #   - MIGRATION: Switch to SeaweedFS S3 storage in Story 5.1
  #
  # Backup Strategy:
  #   - PostgreSQL directus_db: Via Duplicati automated backups
  #   - File uploads volume: borgstack_directus_uploads backed up by Duplicati
  # ==========================================================================
  directus:
    image: directus/directus:11
    container_name: borgstack_directus
    restart: unless-stopped
    networks:
      - borgstack_internal  # Access to PostgreSQL, Redis
      - borgstack_external  # Access from Caddy reverse proxy
    # ⚠️  NO ports section in production - web UI accessed via Caddy reverse proxy
    # ℹ️  For local development, add port mapping in docker-compose.override.yml
    volumes:
      # File uploads directory (local storage - migrating to S3 in Story 5.1)
      - borgstack_directus_uploads:/directus/uploads
    environment:
      # ======================================================================
      # Database Configuration (PostgreSQL)
      # ======================================================================
      DB_CLIENT: pg
      DB_HOST: postgresql
      DB_PORT: 5432
      DB_DATABASE: directus_db
      DB_USER: directus_user
      DB_PASSWORD: ${DIRECTUS_DB_PASSWORD}

      # ======================================================================
      # Redis Cache Configuration
      # ======================================================================
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      CACHE_ENABLED: "true"
      CACHE_STORE: redis
      CACHE_TTL: "300"  # 5 minutes default cache TTL

      # ======================================================================
      # Directus Core Configuration
      # ======================================================================
      # Instance identifier (UUID format) - must be unique per deployment
      KEY: ${DIRECTUS_KEY}
      # Auth token signing secret (32+ characters) - protects authentication tokens
      SECRET: ${DIRECTUS_SECRET}
      # Admin user credentials (first-time setup)
      ADMIN_EMAIL: ${DIRECTUS_ADMIN_EMAIL}
      ADMIN_PASSWORD: ${DIRECTUS_ADMIN_PASSWORD}
      # Public URL for asset URLs and OAuth callbacks
      PUBLIC_URL: https://${DIRECTUS_HOST}
      # WebSocket support for real-time updates
      WEBSOCKETS_ENABLED: "true"

      # ======================================================================
      # File Storage Configuration
      # ======================================================================
      # MIGRATION: Switch to SeaweedFS S3 storage in Story 5.1
      # Current: Local volume storage
      # Future: S3-compatible storage (see config/directus/s3-storage.env.example)
      STORAGE_LOCATIONS: local
    depends_on:
      postgresql:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://127.0.0.1:8055/server/health || exit 1"]
      interval: 60s
      timeout: 10s
      retries: 10
      start_period: 180s
      # Increased from 90s to 180s for CI environment compatibility
      # Test script uses 600s timeout with migration detection
      # Rationale for 180s start_period:
      #   - Database migrations: ~20-30s (Knex.js schema creation and updates)
      #   - Extension initialization: ~10s (pgvector and other extensions)
      #   - Redis connection: ~5s (cache initialization)
      #   - CI environment overhead: +60-90s additional buffer for CI/CD environments
      #   - Express server startup: ~10s (Node.js application server)
      #   - Cache warming: ~20-30s (initial cache population)
      # Total: ~65-85s local, ~125-175s in CI (180s provides safety margin)

  # ==========================================================================
  # FileFlows - Media Processing Automation
  # ==========================================================================
  # Automated media file conversion and processing platform with FFmpeg
  # Image: revenz/fileflows:25.09
  #
  # Purpose:
  #   - Automated media file conversion and processing workflows
  #   - FFmpeg-based transcoding (video, audio, image)
  #   - Directory watching for automatic processing
  #   - Integration with Directus and n8n for media workflow automation
  #
  # Architecture:
  #   - Node.js application with FFmpeg processing engine
  #   - Port 5000: Web UI (Flow Designer) + API endpoint
  #   - File processing: Input directory monitoring → Processing → Output directory
  #   - Flow designer: Visual workflow builder for processing pipelines
  #
  # Storage Strategy:
  #   - Story 4.2: Local volume storage (borgstack_fileflows_input/output/temp)
  #   - Story 5.1: Migration to SeaweedFS S3-compatible storage (planned)
  #   - MIGRATION: Switch to SeaweedFS S3 storage in Story 5.1
  #
  # Integration Patterns:
  #   - Directus → n8n → FileFlows: Trigger processing when media uploaded to CMS
  #   - FileFlows → n8n: Webhook notification on processing completion
  #   - n8n → Directus: Update CMS with processed media URL
  #
  # Access:
  #   - Web UI: https://fileflows.{DOMAIN} (via Caddy reverse proxy)
  #   - Flow Designer: https://fileflows.{DOMAIN}/flows
  #   - Processing Nodes: Configured in web UI (local server node)
  #
  # Security:
  #   - NO port exposure to host (access via Caddy only)
  #   - File permissions managed with PUID/PGID
  #   - Network isolation (internal for future SeaweedFS, external for Caddy)
  #   - HTTPS enforced via Caddy with automatic Let's Encrypt SSL
  #
  # Processing Capabilities:
  #   - Video transcoding: H.264/H.265 encoding, resolution scaling
  #   - Audio processing: Normalization (loudnorm), format conversion
  #   - Image optimization: WebP conversion, resizing, compression
  #   - Batch processing: Queue multiple files with concurrent processing
  #
  # Backup Strategy:
  #   - Configuration: borgstack_fileflows_data backed up by Duplicati
  #   - Processing logs: borgstack_fileflows_logs backed up by Duplicati
  #   - Media files: Input/output volumes backed up by Duplicati
  # ==========================================================================
  fileflows:
    image: revenz/fileflows:25.09
    container_name: borgstack_fileflows
    restart: unless-stopped
    networks:
      - borgstack_internal  # For future SeaweedFS access (Story 5.1)
      - borgstack_external  # Access from Caddy reverse proxy
    # ⚠️  NO ports section in production - web UI accessed via Caddy reverse proxy
    # ℹ️  For local development, add port mapping in docker-compose.override.yml
    volumes:
      # Application data and configuration
      - borgstack_fileflows_data:/app/Data
      # Processing logs
      - borgstack_fileflows_logs:/app/Logs
      # Temporary processing workspace (scratch space for FFmpeg)
      - borgstack_fileflows_temp:/temp
      # Media input directory (watch directory for new files)
      # MIGRATION: Switch to SeaweedFS S3 storage in Story 5.1
      - borgstack_fileflows_input:/input
      # Media output directory (processed files)
      # MIGRATION: Switch to SeaweedFS S3 storage in Story 5.1
      - borgstack_fileflows_output:/output
    environment:
      # ======================================================================
      # FileFlows Core Configuration
      # ======================================================================
      # Timezone for log timestamps
      TZ: ${TZ:-America/Sao_Paulo}
      # File permission management (UID/GID for container user)
      PUID: ${PUID:-1000}
      PGID: ${PGID:-1000}
      # FileFlows base URL (for reverse proxy routing)
      BaseUrl: https://${FILEFLOWS_HOST}
      # Temp directory path (for FFmpeg processing workspace)
      TempPath: /temp
      # Log level (Trace, Debug, Information, Warning, Error, Critical)
      LogLevel: ${FILEFLOWS_LOG_LEVEL:-Information}

      # ======================================================================
      # File Storage Configuration (Local Volumes - Story 4.2)
      # ======================================================================
      # MIGRATION: Switch to SeaweedFS S3 storage in Story 5.1
      # See config/fileflows/s3-storage.env.example for S3 configuration template
      # Current: Local Docker volumes
      # Future: S3-compatible storage via SeaweedFS

      # Optional: License key for commercial features
      # LicenseKey: ${FILEFLOWS_LICENSE_KEY}
    depends_on:
      caddy:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
      # Start period allows application initialization (Node.js startup, FFmpeg verification)

#   (Additional services: seaweedfs, duplicati)

networks:
  borgstack_internal:
    name: borgstack_internal
    driver: bridge
    internal: true
    # ════════════════════════════════════════════════════════════════════════════
    # INTERNAL NETWORK - Service-to-Service Communication
    # ════════════════════════════════════════════════════════════════════════════
    # Purpose: Secure backend communication between application services and databases
    # Security: internal: true prevents external host access - defense in depth
    #
    # Services connecting to this network (to be implemented in future stories):
    #   - PostgreSQL (Story 1.3)       - Database for n8n, Chatwoot, Directus, Evolution API
    #   - MongoDB (Story 1.4)          - Database for Lowcoder
    #   - Redis (Story 1.7)            - Cache/queue for all services
    #   - n8n (Story 2.1)              - Workflow automation (internal + external)
    #   - Chatwoot (Story 3.1)         - Customer service (internal + external)
    #   - Evolution API (Story 2.2)    - WhatsApp API (internal + external)
    #   - Lowcoder (Story 3.3)         - App builder (internal + external)
    #   - Directus (Story 4.1)         - Headless CMS (internal + external)
    #   - FileFlows (Story 4.2)        - Media processing (internal + external)
    #   - SeaweedFS (Story 1.6)        - Object storage (internal + external)
    #   - Duplicati (Story 1.8)        - Backup system (internal only)
    #
    # Service Discovery (Docker DNS - automatic):
    #   Connection strings use service names directly, no manual IP configuration:
    #     - PostgreSQL: postgresql:5432
    #     - MongoDB:    mongodb:27017
    #     - Redis:      redis:6379
    #   Example: DB_HOST=postgresql DB_PORT=5432 (DNS resolves automatically)
    #
    # Port Exposure Policy:
    #   ✅ Databases/caches: NO ports section in production (internal access only)
    #   ❌ Never expose database ports to host: prevents unauthorized direct access
    #   ℹ️  Dev port mappings allowed in docker-compose.override.yml for debugging

  borgstack_external:
    name: borgstack_external
    driver: bridge
    # ════════════════════════════════════════════════════════════════════════════
    # EXTERNAL NETWORK - Reverse Proxy Access
    # ════════════════════════════════════════════════════════════════════════════
    # Purpose: Internet-facing traffic routing through Caddy reverse proxy
    # Security: Only Caddy exposes ports 80/443 to host - single entry point
    #
    # Services connecting to this network:
    #   - Caddy (Story 1.5)            - HTTPS termination, routing (ONLY service exposing ports to host)
    #   - Application services         - Connect to BOTH networks for DB access + external routing
    #
    # Multi-Network Pattern (services needing both internal DB access and external web access):
    #   services:
    #     n8n:
    #       networks:
    #         - borgstack_internal    # For PostgreSQL, Redis connections
    #         - borgstack_external    # For Caddy reverse proxy routing
    #
    # Port Mapping Strategy:
    #   ✅ Only Caddy exposes ports 80/443 to host (implemented in Story 1.5)
    #   ✅ All external access flows through Caddy reverse proxy
    #   ℹ️  Application services accessed via: https://service.yourdomain.com (Caddy routes internally)
    #   ℹ️  Dev environment: docker-compose.override.yml may expose additional ports for debugging

# Volumes will be added as services are implemented
# All volumes must use the borgstack_ prefix
volumes:
  borgstack_postgresql_data:
    # PostgreSQL data directory
    # Contains all databases: n8n_db, chatwoot_db, directus_db, evolution_db
    # Backed up by Duplicati (Story 5.2)
    # Manual backup: docker compose exec postgresql pg_dumpall -U postgres > backup.sql

  borgstack_redis_data:
    # Redis data directory
    # Contains: RDB snapshots (dump.rdb) and AOF file (appendonly.aof)
    # Persistence strategy: RDB for fast restarts + AOF for durability (max 1 sec data loss)
    # Backed up by Duplicati (Story 5.2)
    # Manual backup: docker compose exec redis redis-cli -a ${REDIS_PASSWORD} SAVE

  borgstack_caddy_data:
    # Caddy data directory
    # Contains: SSL/TLS certificates from Let's Encrypt, ACME account data
    # Certificate auto-renewal: 30 days before expiration (no manual intervention)
    # Backed up by Duplicati (Story 5.2) - critical for certificate continuity
    # View certificates: docker compose exec caddy ls -lah /data/caddy/certificates/

  borgstack_caddy_config:
    # Caddy auto-saved configuration directory
    # Contains: Caddy's internal JSON representation of Caddyfile
    # Auto-generated on startup and config reload
    # Not critical for backups (regenerated from Caddyfile on restart)

  borgstack_mongodb_data:
    # MongoDB data directory
    # Contains: Lowcoder database collections and indexes
    # Backed up by Duplicati (Story 5.2)
    # Manual backup: docker compose exec -T mongodb mongodump --username admin --password ${MONGODB_ROOT_PASSWORD} --authenticationDatabase admin --out /backup/$(date +%Y%m%d_%H%M%S)
    # Manual restore: docker compose exec -T mongodb mongorestore --username admin --password ${MONGODB_ROOT_PASSWORD} --authenticationDatabase admin /backup/BACKUP_FOLDER_NAME

  borgstack_n8n_data:
    # n8n workflow automation data directory
    # Contains: Workflow definitions, credentials (encrypted), custom nodes, executions history
    # Backed up by Duplicati (Story 5.2)
    # CRITICAL: Contains encrypted credentials - backup N8N_ENCRYPTION_KEY separately
    # Manual backup: docker compose exec -T n8n tar czf - /home/node/.n8n > n8n-backup-$(date +%Y%m%d).tar.gz

  borgstack_evolution_instances:
    # Evolution API WhatsApp instance data directory
    # Contains: WhatsApp session data, QR codes, instance configurations, authentication tokens
    # Backed up by Duplicati (Story 5.2)
    # CRITICAL: Contains WhatsApp session credentials - loss requires re-authentication via QR code
    # Manual backup: docker compose exec -T evolution tar czf - /evolution/instances > evolution-backup-$(date +%Y%m%d).tar.gz

  borgstack_chatwoot_storage:
    # Chatwoot storage directory
    # Contains: File uploads, attachments, agent avatars, customer profile images
    # Backed up by Duplicati (Story 5.2)
    # Manual backup: docker compose exec -T chatwoot tar czf - /app/storage > chatwoot-storage-backup-$(date +%Y%m%d).tar.gz

  borgstack_chatwoot_public:
    # Chatwoot public assets directory
    # Contains: Rails compiled assets, webpacker bundles, JavaScript/CSS files
    # Auto-regenerated on container restart (asset precompilation)
    # Not critical for backups (can be regenerated from image)

  borgstack_lowcoder_stacks:
    # Lowcoder application stacks directory
    # Contains: Custom application definitions, custom components, query configurations, assets
    # Backed up by Duplicati (Story 5.2)
    # CRITICAL: Contains all custom applications and datasource connections
    # Manual backup: docker compose exec -T lowcoder tar czf - /lowcoder-stacks > lowcoder-backup-$(date +%Y%m%d).tar.gz

  borgstack_directus_uploads:
    # Directus file uploads directory
    # Contains: Uploaded media files, assets, and documents
    # Backed up by Duplicati (Story 5.2)
    # MIGRATION: Will be replaced with SeaweedFS S3 storage in Story 5.1
    # Manual backup: docker compose exec -T directus tar czf - /directus/uploads > directus-uploads-backup-$(date +%Y%m%d).tar.gz

  borgstack_fileflows_data:
    # FileFlows application data and configuration directory
    # Contains: Flow definitions, processing node configurations, application settings
    # Backed up by Duplicati (Story 5.2)
    # CRITICAL: Contains all processing workflows and configurations
    # Manual backup: docker compose exec -T fileflows tar czf - /app/Data > fileflows-data-backup-$(date +%Y%m%d).tar.gz

  borgstack_fileflows_logs:
    # FileFlows processing logs directory
    # Contains: Processing history, error logs, job execution records
    # Backed up by Duplicati (Story 5.2)
    # Useful for troubleshooting failed processing jobs
    # Manual backup: docker compose exec -T fileflows tar czf - /app/Logs > fileflows-logs-backup-$(date +%Y%m%d).tar.gz

  borgstack_fileflows_temp:
    # FileFlows temporary processing workspace
    # Contains: Scratch files during active FFmpeg transcoding
    # NOT backed up (temporary workspace, auto-cleaned)
    # Auto-cleanup: FileFlows cleans up temp files after job completion
    # Disk space: Ensure adequate space for largest media file × concurrent jobs

  borgstack_fileflows_input:
    # FileFlows media input directory (watch directory)
    # Contains: Media files awaiting processing (user uploads, Directus uploads)
    # Backed up by Duplicati (Story 5.2)
    # MIGRATION: Will be replaced with SeaweedFS S3 storage in Story 5.1
    # Manual backup: docker compose exec -T fileflows tar czf - /input > fileflows-input-backup-$(date +%Y%m%d).tar.gz

  borgstack_fileflows_output:
    # FileFlows processed media output directory
    # Contains: Transcoded/optimized media files ready for delivery
    # Backed up by Duplicati (Story 5.2)
    # MIGRATION: Will be replaced with SeaweedFS S3 storage in Story 5.1
    # Manual backup: docker compose exec -T fileflows tar czf - /output > fileflows-output-backup-$(date +%Y%m%d).tar.gz

# Additional volumes (to be added in future stories):
#   borgstack_seaweedfs_data:
#   borgstack_duplicati_data:
