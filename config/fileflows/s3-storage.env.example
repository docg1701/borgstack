# ============================================================================
# FileFlows S3 Storage Configuration Template
# ============================================================================
#
# This template is for Story 5.1 (SeaweedFS S3 Storage Migration).
# DO NOT apply these settings in Story 4.2 - SeaweedFS is not yet deployed.
#
# Purpose:
#   - Migration template for transitioning from local volumes to SeaweedFS S3
#   - Will be applied when Story 5.1 (SeaweedFS deployment) is complete
#
# Migration Timeline:
#   - Story 4.2: Local volume storage (borgstack_fileflows_input/output/temp)
#   - Story 5.1: Migrate to SeaweedFS S3-compatible storage
#
# ============================================================================

# ============================================================================
# SeaweedFS S3 Configuration
# ============================================================================

# S3 Storage Type
# Set to "s3" to enable S3-compatible storage
# Default: "local" (local volume storage used in Story 4.2)
STORAGE_TYPE=s3

# S3 Endpoint (SeaweedFS S3 Gateway)
# Internal Docker network address for SeaweedFS S3 gateway
# Port 8333 is the default S3-compatible API port for SeaweedFS
S3_ENDPOINT=http://seaweedfs:8333

# S3 Bucket Name
# Shared bucket for all BorgStack file storage
# SeaweedFS organizes files using prefixes (see below)
S3_BUCKET=borgstack

# S3 Prefix for Input Files
# Directory path in S3 bucket for input media files (watch directory)
# FileFlows monitors this prefix for new files to process
S3_INPUT_PREFIX=fileflows/input/

# S3 Prefix for Output Files
# Directory path in S3 bucket for processed media files
# FileFlows writes transcoded/optimized files to this prefix
S3_OUTPUT_PREFIX=fileflows/output/

# S3 Prefix for Temporary Files
# Directory path in S3 bucket for temporary processing workspace
# FileFlows uses this as scratch space during FFmpeg transcoding
# Files in this prefix are automatically cleaned up after processing
S3_TEMP_PREFIX=fileflows/temp/

# S3 Access Credentials (SeaweedFS)
# Access key ID for S3 authentication
# Obtain from Story 5.1 SeaweedFS deployment (.env SEAWEEDFS_ACCESS_KEY)
S3_ACCESS_KEY=${SEAWEEDFS_ACCESS_KEY}

# S3 Secret Key for authentication
# Obtain from Story 5.1 SeaweedFS deployment (.env SEAWEEDFS_SECRET_KEY)
S3_SECRET_KEY=${SEAWEEDFS_SECRET_KEY}

# ============================================================================
# S3 Advanced Configuration (Optional)
# ============================================================================

# S3 Region
# SeaweedFS does not require a specific region, but some S3 clients expect it
# Default: "us-east-1" (standard S3 default region)
S3_REGION=us-east-1

# S3 Path Style Access
# Use path-style URLs (http://endpoint/bucket/key) instead of virtual-hosted (http://bucket.endpoint/key)
# SeaweedFS supports both, but path-style is more compatible with internal Docker networks
# Default: true
S3_PATH_STYLE=true

# S3 Use SSL/TLS
# Enable HTTPS for S3 API requests
# Set to false for internal Docker network (http://seaweedfs:8333)
# Set to true for external S3 services (https://s3.amazonaws.com)
# Default: false (internal Docker network)
S3_USE_SSL=false

# ============================================================================
# Migration Instructions (Story 5.1)
# ============================================================================
#
# Step 1: Ensure SeaweedFS is deployed and healthy
#   docker compose ps seaweedfs
#   Expected: Status "Up (healthy)"
#
# Step 2: Copy existing files from local volumes to SeaweedFS S3
#   # Input files
#   docker compose exec seaweedfs s3cmd put --recursive \
#     /mnt/borgstack_fileflows_input/ \
#     s3://borgstack/fileflows/input/
#
#   # Output files
#   docker compose exec seaweedfs s3cmd put --recursive \
#     /mnt/borgstack_fileflows_output/ \
#     s3://borgstack/fileflows/output/
#
# Step 3: Update docker-compose.yml
#   - Remove local volume mounts (/input, /output, /temp)
#   - Add S3 environment variables from this file to fileflows service
#
# Step 4: Restart FileFlows container
#   docker compose up -d fileflows
#
# Step 5: Verify S3 connectivity
#   docker compose logs fileflows --tail=50 | grep -i "s3\|storage"
#   Expected: "S3 storage initialized successfully"
#
# Step 6: Test processing with new file
#   # Upload test file to SeaweedFS S3
#   docker compose exec seaweedfs s3cmd put test-video.mp4 s3://borgstack/fileflows/input/
#
#   # Monitor processing in FileFlows UI
#   https://fileflows.${DOMAIN}/processing
#
# Step 7: Verify processed file in S3 output
#   docker compose exec seaweedfs s3cmd ls s3://borgstack/fileflows/output/
#   Expected: Processed file appears in output prefix
#
# Step 8: Archive local volumes (after verification)
#   docker volume rm borgstack_fileflows_input
#   docker volume rm borgstack_fileflows_output
#   docker volume rm borgstack_fileflows_temp
#
# ============================================================================
# Rollback Plan (If Migration Fails)
# ============================================================================
#
# If S3 migration encounters issues, rollback to local volumes:
#
# Step 1: Stop FileFlows container
#   docker compose stop fileflows
#
# Step 2: Restore local volume configuration in docker-compose.yml
#   volumes:
#     - borgstack_fileflows_input:/input
#     - borgstack_fileflows_output:/output
#     - borgstack_fileflows_temp:/temp
#
# Step 3: Remove S3 environment variables from docker-compose.yml
#
# Step 4: Restart FileFlows
#   docker compose up -d fileflows
#
# Step 5: Verify local storage is working
#   docker compose logs fileflows --tail=50
#   Expected: "Local storage initialized successfully"
#
# ============================================================================
# Additional Notes
# ============================================================================
#
# - This template is for planning purposes (Story 4.2)
# - Actual migration will be performed in Story 5.1
# - Keep this file updated if S3 configuration requirements change
# - Ensure SEAWEEDFS_ACCESS_KEY and SEAWEEDFS_SECRET_KEY are set in .env before migration
#
# ============================================================================
